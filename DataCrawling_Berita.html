

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Crawling Berita &#8212; Aderisa Dyta Okvianti 200411100013</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'DataCrawling_Berita';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="PageRank" href="Perhitungan_PageRank.html" />
    <link rel="prev" title="Modelling LDA" href="Modelling_LDA.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/image.jpg" class="logo__image only-light" alt="Aderisa Dyta Okvianti 200411100013 - Home"/>
    <script>document.write(`<img src="_static/image.jpg" class="logo__image only-dark" alt="Aderisa Dyta Okvianti 200411100013 - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    SELAMAT DATANG DI WEBSITE MATA KULIAH PENCARIAN DAN PENAMBANGAN WEB
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Crawling_PTA.html">Crawling PTA</a></li>
<li class="toctree-l1"><a class="reference internal" href="Preprocessing_PTA.html">Preprocessing_PTA</a></li>
<li class="toctree-l1"><a class="reference internal" href="Modelling_LDA.html">Modelling LDA</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Crawling Berita</a></li>






<li class="toctree-l1"><a class="reference internal" href="Perhitungan_PageRank.html">PageRank</a></li>
<li class="toctree-l1"><a class="reference internal" href="Crawling_BeritaSatu.html">Crawling Berita</a></li>





</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/AderisaDyta/Laporan_ppw" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/AderisaDyta/Laporan_ppw/issues/new?title=Issue%20on%20page%20%2FDataCrawling_Berita.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/DataCrawling_Berita.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Crawling Berita</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Crawling Berita</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#import-library"><strong>Import Library</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#proses-crawling-berita"><strong>Proses Crawling Berita</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#preprocessing"><strong>Preprocessing</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#tf-idf"><strong>TF-IDF</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#cosine-similarity"><strong>Cosine Similarity</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#closeness-centrality"><strong>Closeness Centrality</strong></a></li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="crawling-berita">
<h1>Crawling Berita<a class="headerlink" href="#crawling-berita" title="Permalink to this heading">#</a></h1>
</section>
<section id="import-library">
<h1><strong>Import Library</strong><a class="headerlink" href="#import-library" title="Permalink to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>Sastrawi
<span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">word_tokenize</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
<span class="kn">from</span> <span class="nn">Sastrawi.Stemmer.StemmerFactory</span> <span class="kn">import</span> <span class="n">StemmerFactory</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">csv</span>

<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;stopwords&#39;</span><span class="p">)</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;punkt&#39;</span><span class="p">)</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: Sastrawi in /usr/local/lib/python3.10/dist-packages (1.0.1)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[nltk_data] Downloading package stopwords to /root/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package punkt to /root/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
</pre></div>
</div>
</div>
</div>
</section>
<section id="proses-crawling-berita">
<h1><strong>Proses Crawling Berita</strong><a class="headerlink" href="#proses-crawling-berita" title="Permalink to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#melakukan web scraping pada halaman berita yang berasal dari URL</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span> <span class="nn">nltk</span>

<span class="c1"># Unduh konten halaman web berita</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://www.antaranews.com/berita/3799398/mukti-ali-dituntut-6-tahun-penjara&quot;</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="n">html</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">text</span>

<span class="c1"># Parsing halaman web menggunakan BeautifulSoup</span>
<span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">html</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>

<span class="c1"># Ekstraksi teks dari elemen-elemen yang berisi berita</span>
<span class="n">article</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;div&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s2">&quot;post-content clearfix&quot;</span><span class="p">)</span>  <span class="c1"># Sesuaikan dengan struktur HTML halaman web berita</span>

<span class="c1"># Periksa apakah elemen article ada sebelum mencoba mengambil teksnya</span>
<span class="k">if</span> <span class="n">article</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">article_text</span> <span class="o">=</span> <span class="n">article</span><span class="o">.</span><span class="n">get_text</span><span class="p">()</span>

    <span class="c1"># Tokenisasi teks menjadi kalimat menggunakan nltk</span>
    <span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;punkt&#39;</span><span class="p">)</span>  <span class="c1"># Pastikan Anda sudah mengunduh tokenisasi kalimat nltk</span>
    <span class="n">sentences</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">sent_tokenize</span><span class="p">(</span><span class="n">article_text</span><span class="p">)</span>

    <span class="c1"># Cetak kalimat-kalimat</span>
    <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Elemen berita tidak ditemukan&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>				Jakarta (ANTARA) - Jaksa penuntut umum (JPU) pada Kejaksaan Agung (Kejagung) RI menuntut Account Director of Integrated Account Departement PT Huawei Tech Investment Mukti Ali selama 6 tahun dan membayar denda Rp500 juta subsider 6 bulan pidana kurungan dalam perkara korupsi BTS 4G Kementerian Komunikasi dan Informatika (Kemenkominfo).
&quot;Menjatuhkan pidana terhadap terdakwa Mukti Ali selama 6 tahun dikurangi sepenuhnya dengan lamanya terdakwa ditahan dengan perintah agar terdakwa tetap dilakukan penahanan di rutan,&quot; kata jaksa dalam persidangan di Pengadilan Tindak Pidana Korupsi (Tipikor) pada Pengadilan Negeri Jakarta Pusat, Senin.
Jaksa menyatakan bahwa terdakwa Mukti Ali terbukti secara sah dan meyakinkan bersalah menurut hukum turut serta dalam melakukan tindak pidana korupsi BTS 4G Kementerian Komunikasi dan Informatika (Kemenkominfo).
Mukti didakwa telah melanggar Pasal 2 ayat (1) juncto Pasal 18 Undang-Undang Nomor 31 Tahun 1999 tentang Pemberantasan Tindak Pidana Korupsi sebagaimana diubah dengan UU No.
20 Tahun 2001 jo.
Pasal 55 ayat (1) ke-1 KUHP.
Sementara itu, hal-hal yang memberatkan terdakwa adalah perbuatannya tidak mendukung program pemerintah dalam rangka penyelenggaraan negara yang bersih dari korupsi, kolusi, dan nepotisme.
&quot;Perbuatan terdakwa bersama-sama dengan terdakwa lain telah mengakibatkan kerugian keuangan negara sebesar Rp8.032.084.133.795,51,&quot; ungkap jaksa.
Adapun hal-hal yang meringankan Mukti Ali adalah terdakwa belum pernah dihukum, bersikap sopan selama persidangan, dan tidak menikmati hasil dari tindak pidana korupsi.
Baca juga: Irwan Hermawan dituntut 6 tahun penjara terkait korupsi BTS 4G
Baca juga: Galumbang Menak dituntut 15 tahun penjara dalam kasus BTS 4G
 
Sidang tuntutan ini digelar bersamaan dengan tuntutan dua terdakwa lainnya, yakni Komisaris PT Solitech Media Sinergy Irwan Hermawan dan eks Direktur Utama PT Mora Telematika Indonesia Galumbang Menak Simanjuntak.
Irwan Hermawan dituntut pidana penjara selama 6 tahun, sementara Galumbang Menak dituntut 15 tahun.
Para terdakwa diduga melakukan tindak pidana korupsi penyediaan infrastruktur base transceiver station (BTS) 4G dan infrastruktur pendukung paket 1, 2, 3, 4, dan 5 BAKTI Kemenkominfo pada tahun 2020–2022.
Pada surat dakwaan disebutkan bahwa sejumlah pihak mendapat keuntungan dari proyek pembangunan tersebut, yaitu mantan Menteri Kominfo Johnny G. Plate menerima uang sebesar Rp17.848.308.000,00; mantan Direktur Utama Bakti Kominfo Anang Achmad Latif menerima uang Rp5 miliar; dan tenaga ahli Human Development Universitas Indonesia Yohan Suryanto menerima Rp453.608.400,00.
Selanjutnya, Irwan Hermawan selaku Komisaris PT Solitechmedia Sinergy menerima Rp119 miliar; Windi Purnama selaku Direktur PT Multimedia Berdikari Sejahtera menerima Rp500 juta; Muhammad Yusrizki selaku Direktur PT Basis Utama Prima menerima Rp50 miliar dan 2,5 juta dolar AS; Konsorsium FiberHome PT Telkominfra PT Multi Trans Data (PT MTD) untuk Paket 1 dan 2 menerima Rp2.940.870.824.490,00; Konsorsium Lintasarta Huawei SEI untuk paket 3 menerima Rp1.584.914.620.955,00; dan Konsorsium IBS dan ZTE Paket 4 dan 5 mendapat Rp3.504.518.715.600,00.Pewarta: Rivan Awal LinggaEditor: D.Dj.
Kliwantoro				COPYRIGHT © ANTARA 2023
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[nltk_data] Downloading package punkt to /root/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
</pre></div>
</div>
</div>
</div>
</section>
<section id="preprocessing">
<h1><strong>Preprocessing</strong><a class="headerlink" href="#preprocessing" title="Permalink to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Lowercasing</span>
<span class="n">article_text</span> <span class="o">=</span> <span class="n">article_text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

<span class="c1"># Cleaning</span>
<span class="n">article_text</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">e</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">article_text</span> <span class="k">if</span> <span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">isalnum</span><span class="p">()</span> <span class="ow">or</span> <span class="n">e</span><span class="o">.</span><span class="n">isspace</span><span class="p">()</span> <span class="ow">or</span> <span class="n">e</span> <span class="o">==</span> <span class="s1">&#39;.&#39;</span><span class="p">))</span>

<span class="c1"># Hapus Angka</span>
<span class="n">article_text</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">char</span> <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">article_text</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">char</span><span class="o">.</span><span class="n">isdigit</span><span class="p">()])</span>

<span class="c1"># Tokenisasi teks menjadi kalimat menggunakan nltk</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;punkt&#39;</span><span class="p">)</span>
<span class="n">sentences</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">sent_tokenize</span><span class="p">(</span><span class="n">article_text</span><span class="p">)</span>

<span class="c1"># Tokenisasi setiap kalimat menjadi kata-kata</span>
<span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[nltk_data] Downloading package punkt to /root/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#custome stopword</span>

<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>

<span class="c1"># Mengambil daftar stopword bahasa Indonesia dari NLTK</span>
<span class="n">stopwords_indonesia</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s2">&quot;indonesian&quot;</span><span class="p">))</span>

<span class="c1"># Sekarang, Anda memiliki daftar stopword yang telah diperbarui</span>
<span class="nb">print</span><span class="p">(</span><span class="n">stopwords_indonesia</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;demikian&#39;, &#39;per&#39;, &#39;masalah&#39;, &#39;setiba&#39;, &#39;rupanya&#39;, &#39;balik&#39;, &#39;sedangkan&#39;, &#39;akhirnya&#39;, &#39;ditujukan&#39;, &#39;pihaknya&#39;, &#39;diantaranya&#39;, &#39;berlainan&#39;, &#39;tentunya&#39;, &#39;soalnya&#39;, &#39;sepantasnyalah&#39;, &#39;baru&#39;, &#39;diperlukan&#39;, &#39;bagian&#39;, &#39;mendapat&#39;, &#39;olehnya&#39;, &#39;penting&#39;, &#39;bertanya-tanya&#39;, &#39;tiba-tiba&#39;, &#39;seperti&#39;, &#39;apalagi&#39;, &#39;secukupnya&#39;, &#39;enggaknya&#39;, &#39;luar&#39;, &#39;dimisalkan&#39;, &#39;mendapatkan&#39;, &#39;sebelumnya&#39;, &#39;sepertinya&#39;, &#39;inilah&#39;, &#39;belumlah&#39;, &#39;kata&#39;, &#39;apabila&#39;, &#39;bagaimanapun&#39;, &#39;sinilah&#39;, &#39;sampaikan&#39;, &#39;tambah&#39;, &#39;siap&#39;, &#39;sekalian&#39;, &#39;melihatnya&#39;, &#39;beri&#39;, &#39;cuma&#39;, &#39;dikatakan&#39;, &#39;apakah&#39;, &#39;dipergunakan&#39;, &#39;kemudian&#39;, &#39;sampai&#39;, &#39;setinggi&#39;, &#39;ibaratnya&#39;, &#39;diingat&#39;, &#39;berikut&#39;, &#39;berawal&#39;, &#39;menanyakan&#39;, &#39;itulah&#39;, &#39;menyampaikan&#39;, &#39;ikut&#39;, &#39;diibaratkan&#39;, &#39;benarkah&#39;, &#39;bermacam&#39;, &#39;artinya&#39;, &#39;sekitar&#39;, &#39;semisalnya&#39;, &#39;semua&#39;, &#39;atas&#39;, &#39;betul&#39;, &#39;nyaris&#39;, &#39;sela&#39;, &#39;sempat&#39;, &#39;setiap&#39;, &#39;tanyanya&#39;, &#39;mulai&#39;, &#39;bulan&#39;, &#39;lima&#39;, &#39;melalui&#39;, &#39;mengira&#39;, &#39;sendirian&#39;, &#39;tersebutlah&#39;, &#39;dibuatnya&#39;, &#39;semula&#39;, &#39;dijelaskan&#39;, &#39;kalaupun&#39;, &#39;pada&#39;, &#39;bisakah&#39;, &#39;padahal&#39;, &#39;pertanyakan&#39;, &#39;ditandaskan&#39;, &#39;sedikit&#39;, &#39;mengapa&#39;, &#39;dipunyai&#39;, &#39;usah&#39;, &#39;berapakah&#39;, &#39;sejumlah&#39;, &#39;seorang&#39;, &#39;menjadi&#39;, &#39;sesegera&#39;, &#39;tampak&#39;, &#39;berlebihan&#39;, &#39;tentulah&#39;, &#39;inikah&#39;, &#39;secara&#39;, &#39;sedang&#39;, &#39;semasa&#39;, &#39;biasa&#39;, &#39;seketika&#39;, &#39;mendatang&#39;, &#39;sana&#39;, &#39;agar&#39;, &#39;nanti&#39;, &#39;dibuat&#39;, &#39;memihak&#39;, &#39;seterusnya&#39;, &#39;bagaikan&#39;, &#39;bermaksud&#39;, &#39;pernah&#39;, &#39;lanjutnya&#39;, &#39;hal&#39;, &#39;bermacam-macam&#39;, &#39;lagian&#39;, &#39;berkali-kali&#39;, &#39;masihkah&#39;, &#39;percuma&#39;, &#39;mula&#39;, &#39;sekaligus&#39;, &#39;seringnya&#39;, &#39;menanti-nanti&#39;, &#39;memperkirakan&#39;, &#39;sepanjang&#39;, &#39;beginilah&#39;, &#39;kelihatannya&#39;, &#39;disini&#39;, &#39;sudah&#39;, &#39;kitalah&#39;, &#39;perlunya&#39;, &#39;haruslah&#39;, &#39;menunjukkan&#39;, &#39;sebaik&#39;, &#39;terus&#39;, &#39;siapakah&#39;, &#39;pertama&#39;, &#39;asalkan&#39;, &#39;begini&#39;, &#39;katakan&#39;, &#39;lainnya&#39;, &#39;menjawab&#39;, &#39;dimaksudnya&#39;, &#39;bertutur&#39;, &#39;menantikan&#39;, &#39;ditegaskan&#39;, &#39;berapalah&#39;, &#39;jauh&#39;, &#39;bersama-sama&#39;, &#39;bila&#39;, &#39;dituturkan&#39;, &#39;seperlunya&#39;, &#39;sejauh&#39;, &#39;jadinya&#39;, &#39;semaunya&#39;, &#39;ini&#39;, &#39;kini&#39;, &#39;manalagi&#39;, &#39;menunjuki&#39;, &#39;dimintai&#39;, &#39;apaan&#39;, &#39;hampir&#39;, &#39;dikatakannya&#39;, &#39;inginkah&#39;, &#39;manakala&#39;, &#39;ungkap&#39;, &#39;malahan&#39;, &#39;bagi&#39;, &#39;mengingat&#39;, &#39;jikalau&#39;, &#39;sebutlah&#39;, &#39;semata-mata&#39;, &#39;kok&#39;, &#39;hanyalah&#39;, &#39;aku&#39;, &#39;tentu&#39;, &#39;tidaklah&#39;, &#39;dini&#39;, &#39;apa&#39;, &#39;ungkapnya&#39;, &#39;sajalah&#39;, &#39;cara&#39;, &#39;terlebih&#39;, &#39;selaku&#39;, &#39;waduh&#39;, &#39;diberi&#39;, &#39;meminta&#39;, &#39;tegasnya&#39;, &#39;disebutkan&#39;, &#39;bapak&#39;, &#39;demikianlah&#39;, &#39;menyiapkan&#39;, &#39;serta&#39;, &#39;anda&#39;, &#39;selama-lamanya&#39;, &#39;katakanlah&#39;, &#39;semakin&#39;, &#39;waktu&#39;, &#39;seseorang&#39;, &#39;dimaksud&#39;, &#39;kemungkinannya&#39;, &#39;termasuk&#39;, &#39;sekali-kali&#39;, &#39;amatlah&#39;, &#39;berupa&#39;, &#39;kapankah&#39;, &#39;disebut&#39;, &#39;dilihat&#39;, &#39;justru&#39;, &#39;diri&#39;, &#39;menurut&#39;, &#39;menghendaki&#39;, &#39;dalam&#39;, &#39;akankah&#39;, &#39;cukupkah&#39;, &#39;akhir&#39;, &#39;lagi&#39;, &#39;masalahnya&#39;, &#39;boleh&#39;, &#39;bermula&#39;, &#39;panjang&#39;, &#39;diperbuatnya&#39;, &#39;dipersoalkan&#39;, &#39;ucap&#39;, &#39;diberikannya&#39;, &#39;yaitu&#39;, &#39;ingat-ingat&#39;, &#39;akhiri&#39;, &#39;disampaikan&#39;, &#39;sekiranya&#39;, &#39;selain&#39;, &#39;diakhiri&#39;, &#39;biasanya&#39;, &#39;ditunjuki&#39;, &#39;sesudah&#39;, &#39;ucapnya&#39;, &#39;sesudahnya&#39;, &#39;menunjuknya&#39;, &#39;se&#39;, &#39;semacam&#39;, &#39;harusnya&#39;, &#39;tersampaikan&#39;, &#39;bersama&#39;, &#39;betulkah&#39;, &#39;mengakhiri&#39;, &#39;berlalu&#39;, &#39;terdapat&#39;, &#39;saya&#39;, &#39;ditunjukkannya&#39;, &#39;didapat&#39;, &#39;bersiap&#39;, &#39;hingga&#39;, &#39;sebisanya&#39;, &#39;seingat&#39;, &#39;tahun&#39;, &#39;kala&#39;, &#39;janganlah&#39;, &#39;tepat&#39;, &#39;tunjuk&#39;, &#39;belakang&#39;, &#39;hendak&#39;, &#39;teringat&#39;, &#39;kedua&#39;, &#39;dimulai&#39;, &#39;yang&#39;, &#39;seolah&#39;, &#39;mempersiapkan&#39;, &#39;semata&#39;, &#39;kira&#39;, &#39;menanti&#39;, &#39;dahulu&#39;, &#39;dialah&#39;, &#39;pastilah&#39;, &#39;sekali&#39;, &#39;naik&#39;, &#39;diperlihatkan&#39;, &#39;berkeinginan&#39;, &#39;dengan&#39;, &#39;kira-kira&#39;, &#39;macam&#39;, &#39;ia&#39;, &#39;sebelum&#39;, &#39;ada&#39;, &#39;mulailah&#39;, &#39;besar&#39;, &#39;perlukah&#39;, &#39;banyak&#39;, &#39;sebagaimana&#39;, &#39;tadi&#39;, &#39;datang&#39;, &#39;sesama&#39;, &#39;sekarang&#39;, &#39;mirip&#39;, &#39;mungkinkah&#39;, &#39;diakhirinya&#39;, &#39;dilalui&#39;, &#39;terjadinya&#39;, &#39;keadaan&#39;, &#39;bolehlah&#39;, &#39;masing-masing&#39;, &#39;pentingnya&#39;, &#39;soal&#39;, &#39;menyangkut&#39;, &#39;seusai&#39;, &#39;bukanlah&#39;, &#39;kapanpun&#39;, &#39;seenaknya&#39;, &#39;memintakan&#39;, &#39;diantara&#39;, &#39;dulu&#39;, &#39;setempat&#39;, &#39;berturut&#39;, &#39;benarlah&#39;, &#39;depan&#39;, &#39;andalah&#39;, &#39;dikarenakan&#39;, &#39;sebab&#39;, &#39;sebutnya&#39;, &#39;terlalu&#39;, &#39;entah&#39;, &#39;sebegini&#39;, &#39;segera&#39;, &#39;wahai&#39;, &#39;semisal&#39;, &#39;ditunjuknya&#39;, &#39;ditanya&#39;, &#39;demi&#39;, &#39;berbagai&#39;, &#39;menjelaskan&#39;, &#39;tidak&#39;, &#39;sebanyak&#39;, &#39;didatangkan&#39;, &#39;memerlukan&#39;, &#39;sebenarnya&#39;, &#39;mana&#39;, &#39;malah&#39;, &#39;jumlah&#39;, &#39;menambahkan&#39;, &#39;hendaknya&#39;, &#39;jangan&#39;, &#39;memastikan&#39;, &#39;begitu&#39;, &#39;semuanya&#39;, &#39;suatu&#39;, &#39;para&#39;, &#39;dikerjakan&#39;, &#39;mau&#39;, &#39;sama-sama&#39;, &#39;merupakan&#39;, &#39;pertama-tama&#39;, &#39;sayalah&#39;, &#39;lamanya&#39;, &#39;terakhir&#39;, &#39;antar&#39;, &#39;nyatanya&#39;, &#39;mengenai&#39;, &#39;kepada&#39;, &#39;rasanya&#39;, &#39;sampai-sampai&#39;, &#39;akulah&#39;, &#39;tertuju&#39;, &#39;bawah&#39;, &#39;lama&#39;, &#39;terdiri&#39;, &#39;jumlahnya&#39;, &#39;berdatangan&#39;, &#39;tahu&#39;, &#39;sebesar&#39;, &#39;khususnya&#39;, &#39;belakangan&#39;, &#39;sewaktu&#39;, &#39;ujarnya&#39;, &#39;kepadanya&#39;, &#39;lah&#39;, &#39;ditunjuk&#39;, &#39;ditambahkan&#39;, &#39;berkenaan&#39;, &#39;sebaiknya&#39;, &#39;dimungkinkan&#39;, &#39;selamanya&#39;, &#39;sesampai&#39;, &#39;berarti&#39;, &#39;kebetulan&#39;, &#39;diperbuat&#39;, &#39;selalu&#39;, &#39;bagaimana&#39;, &#39;diingatkan&#39;, &#39;ditunjukkan&#39;, &#39;dapat&#39;, &#39;bakalan&#39;, &#39;mengibaratkannya&#39;, &#39;kelamaan&#39;, &#39;ke&#39;, &#39;kemungkinan&#39;, &#39;berkata&#39;, &#39;ingin&#39;, &#39;seluruh&#39;, &#39;diucapkan&#39;, &#39;menginginkan&#39;, &#39;katanya&#39;, &#39;kapan&#39;, &#39;diminta&#39;, &#39;pertanyaan&#39;, &#39;berturut-turut&#39;, &#39;guna&#39;, &#39;itu&#39;, &#39;teringat-ingat&#39;, &#39;pun&#39;, &#39;tertentu&#39;, &#39;namun&#39;, &#39;kinilah&#39;, &#39;adalah&#39;, &#39;maka&#39;, &#39;segala&#39;, &#39;awalnya&#39;, &#39;dilakukan&#39;, &#39;menuju&#39;, &#39;dari&#39;, &#39;mampu&#39;, &#39;dituturkannya&#39;, &#39;sebut&#39;, &#39;dikira&#39;, &#39;buat&#39;, &#39;kalian&#39;, &#39;menaiki&#39;, &#39;dua&#39;, &#39;sangat&#39;, &#39;keinginan&#39;, &#39;memberikan&#39;, &#39;memperlihatkan&#39;, &#39;jelaslah&#39;, &#39;pukul&#39;, &#39;sejak&#39;, &#39;persoalan&#39;, &#39;sudahlah&#39;, &#39;dipastikan&#39;, &#39;terhadap&#39;, &#39;sendirinya&#39;, &#39;sesuatu&#39;, &#39;apatah&#39;, &#39;paling&#39;, &#39;minta&#39;, &#39;sekalipun&#39;, &#39;mereka&#39;, &#39;saling&#39;, &#39;sesaat&#39;, &#39;toh&#39;, &#39;menegaskan&#39;, &#39;keluar&#39;, &#39;tanya&#39;, &#39;sesuatunya&#39;, &#39;sepantasnya&#39;, &#39;bilakah&#39;, &#39;sebaliknya&#39;, &#39;punya&#39;, &#39;kecil&#39;, &#39;mampukah&#39;, &#39;mengetahui&#39;, &#39;nantinya&#39;, &#39;sini&#39;, &#39;jika&#39;, &#39;tentang&#39;, &#39;misalnya&#39;, &#39;hendaklah&#39;, &#39;antaranya&#39;, &#39;akan&#39;, &#39;menyebutkan&#39;, &#39;mendatangkan&#39;, &#39;rata&#39;, &#39;berapapun&#39;, &#39;terasa&#39;, &#39;beginikah&#39;, &#39;seberapa&#39;, &#39;begitupun&#39;, &#39;siapa&#39;, &#39;tinggi&#39;, &#39;tiga&#39;, &#39;bagaimanakah&#39;, &#39;mempertanyakan&#39;, &#39;ditanyai&#39;, &#39;sendiri&#39;, &#39;masih&#39;, &#39;mengingatkan&#39;, &#39;sedemikian&#39;, &#39;karena&#39;, &#39;memulai&#39;, &#39;jawab&#39;, &#39;sama&#39;, &#39;semampunya&#39;, &#39;tiap&#39;, &#39;kelima&#39;, &#39;turut&#39;, &#39;misalkan&#39;, &#39;terbanyak&#39;, &#39;dimaksudkan&#39;, &#39;keterlaluan&#39;, &#39;pak&#39;, &#39;tempat&#39;, &#39;dimaksudkannya&#39;, &#39;antara&#39;, &#39;bolehkah&#39;, &#39;melihat&#39;, &#39;juga&#39;, &#39;kurang&#39;, &#39;perlu&#39;, &#39;kenapa&#39;, &#39;menunjuk&#39;, &#39;ibu&#39;, &#39;berada&#39;, &#39;ingat&#39;, &#39;kesampaian&#39;, &#39;oleh&#39;, &#39;walau&#39;, &#39;sebaik-baiknya&#39;, &#39;memisalkan&#39;, &#39;mempersoalkan&#39;, &#39;beberapa&#39;, &#39;baik&#39;, &#39;kita&#39;, &#39;mengucapkannya&#39;, &#39;sekurang-kurangnya&#39;, &#39;tapi&#39;, &#39;ujar&#39;, &#39;kembali&#39;, &#39;menandaskan&#39;, &#39;selanjutnya&#39;, &#39;dijawab&#39;, &#39;menyeluruh&#39;, &#39;sebuah&#39;, &#39;pantas&#39;, &#39;ketika&#39;, &#39;benar&#39;, &#39;diungkapkan&#39;, &#39;setibanya&#39;, &#39;mengatakannya&#39;, &#39;diketahuinya&#39;, &#39;masing&#39;, &#39;mengibaratkan&#39;, &#39;berakhirlah&#39;, &#39;sambil&#39;, &#39;entahlah&#39;, &#39;terjadi&#39;, &#39;semasih&#39;, &#39;seharusnya&#39;, &#39;bung&#39;, &#39;menanyai&#39;, &#39;tengah&#39;, &#39;sekadarnya&#39;, &#39;kamilah&#39;, &#39;satu&#39;, &#39;bahkan&#39;, &#39;terjadilah&#39;, &#39;begitulah&#39;, &#39;cukuplah&#39;, &#39;berakhirnya&#39;, &#39;meski&#39;, &#39;mengucapkan&#39;, &#39;empat&#39;, &#39;semampu&#39;, &#39;bagai&#39;, &#39;jawabnya&#39;, &#39;berjumlah&#39;, &#39;terdahulu&#39;, &#39;berakhir&#39;, &#39;jadilah&#39;, &#39;diibaratkannya&#39;, &#39;bakal&#39;, &#39;bekerja&#39;, &#39;diucapkannya&#39;, &#39;disebutkannya&#39;, &#39;ibarat&#39;, &#39;atau&#39;, &#39;siapapun&#39;, &#39;tak&#39;, &#39;sekecil&#39;, &#39;misal&#39;, &#39;sebegitu&#39;, &#39;padanya&#39;, &#39;daripada&#39;, &#39;selama&#39;, &#39;dan&#39;, &#39;makin&#39;, &#39;bukan&#39;, &#39;bisa&#39;, &#39;begitukah&#39;, &#39;dia&#39;, &#39;saatnya&#39;, &#39;ditanyakan&#39;, &#39;tegas&#39;, &#39;kamu&#39;, &#39;sejenak&#39;, &#39;diberikan&#39;, &#39;segalanya&#39;, &#39;bersiap-siap&#39;, &#39;telah&#39;, &#39;merasa&#39;, &#39;ternyata&#39;, &#39;wah&#39;, &#39;melakukan&#39;, &#39;terhadapnya&#39;, &#39;menanya&#39;, &#39;sedikitnya&#39;, &#39;meyakini&#39;, &#39;keseluruhannya&#39;, &#39;tandasnya&#39;, &#39;di&#39;, &#39;sehingga&#39;, &#39;memberi&#39;, &#39;sekitarnya&#39;, &#39;setidak-tidaknya&#39;, &#39;dekat&#39;, &#39;hanya&#39;, &#39;berlangsung&#39;, &#39;jelasnya&#39;, &#39;mungkin&#39;, &#39;nah&#39;, &#39;tetap&#39;, &#39;ataukah&#39;, &#39;maupun&#39;, &#39;mengerjakan&#39;, &#39;jelaskan&#39;, &#39;lebih&#39;, &#39;mengatakan&#39;, &#39;supaya&#39;, &#39;tanyakan&#39;, &#39;membuat&#39;, &#39;memperbuat&#39;, &#39;sering&#39;, &#39;untuk&#39;, &#39;berapa&#39;, &#39;lanjut&#39;, &#39;mempergunakan&#39;, &#39;lewat&#39;, &#39;sepihak&#39;, &#39;caranya&#39;, &#39;sebetulnya&#39;, &#39;bukannya&#39;, &#39;menggunakan&#39;, &#39;mengungkapkan&#39;, &#39;awal&#39;, &#39;hari&#39;, &#39;bertanya&#39;, &#39;berkehendak&#39;, &#39;cukup&#39;, &#39;meyakinkan&#39;, &#39;adapun&#39;, &#39;bukankah&#39;, &#39;diperkirakan&#39;, &#39;wong&#39;, &#39;berikutnya&#39;, &#39;terlihat&#39;, &#39;tandas&#39;, &#39;kami&#39;, &#39;pula&#39;, &#39;umum&#39;, &#39;dijelaskannya&#39;, &#39;menyatakan&#39;, &#39;waktunya&#39;, &#39;dipertanyakan&#39;, &#39;sebagai&#39;, &#39;agak&#39;, &#39;diperlukannya&#39;, &#39;kamulah&#39;, &#39;kiranya&#39;, &#39;tiba&#39;, &#39;jelas&#39;, &#39;walaupun&#39;, &#39;itukah&#39;, &#39;kelihatan&#39;, &#39;masa&#39;, &#39;dong&#39;, &#39;jawaban&#39;, &#39;kan&#39;, &#39;saat&#39;, &#39;kalau&#39;, &#39;amat&#39;, &#39;tuturnya&#39;, &#39;sebabnya&#39;, &#39;sebagainya&#39;, &#39;ibaratkan&#39;, &#39;seolah-olah&#39;, &#39;belum&#39;, &#39;ialah&#39;, &#39;karenanya&#39;, &#39;digunakan&#39;, &#39;disinilah&#39;, &#39;tanpa&#39;, &#39;keduanya&#39;, &#39;setelah&#39;, &#39;lain&#39;, &#39;saja&#39;, &#39;enggak&#39;, &#39;jadi&#39;, &#39;kasus&#39;, &#39;bahwa&#39;, &#39;meskipun&#39;, &#39;sangatlah&#39;, &#39;setidaknya&#39;, &#39;tersebut&#39;, &#39;sementara&#39;, &#39;makanya&#39;, &#39;diinginkan&#39;, &#39;adanya&#39;, &#39;inginkan&#39;, &#39;lalu&#39;, &#39;yakin&#39;, &#39;beginian&#39;, &#39;sekadar&#39;, &#39;terkira&#39;, &#39;mendatangi&#39;, &#39;sudahkah&#39;, &#39;sesekali&#39;, &#39;memungkinkan&#39;, &#39;agaknya&#39;, &#39;ataupun&#39;, &#39;jangankan&#39;, &#39;dimulainya&#39;, &#39;pasti&#39;, &#39;bahwasanya&#39;, &#39;melainkan&#39;, &#39;tetapi&#39;, &#39;yakni&#39;, &#39;diketahui&#39;, &#39;keseluruhan&#39;, &#39;berikan&#39;, &#39;menuturkan&#39;, &#39;merekalah&#39;, &#39;dimulailah&#39;, &#39;harus&#39;, &#39;setengah&#39;, &#39;umumnya&#39;, &#39;serupa&#39;, &#39;usai&#39;, &#39;berujar&#39;, &#39;sekurangnya&#39;, &#39;terutama&#39;, &#39;pihak&#39;, &#39;tampaknya&#39;, &#39;dirinya&#39;, &#39;tidakkah&#39;, &#39;rasa&#39;, &#39;asal&#39;, &#39;sebagian&#39;, &#39;tadinya&#39;, &#39;gunakan&#39;, &#39;seluruhnya&#39;, &#39;mulanya&#39;, &#39;tutur&#39;, &#39;memang&#39;, &#39;kalaulah&#39;, &#39;tambahnya&#39;, &#39;mempunyai&#39;}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Stopword Removal</span>
<span class="n">stop_words</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">&#39;indonesian&#39;</span><span class="p">))</span>
<span class="n">filtered_sentences</span> <span class="o">=</span> <span class="p">[]</span>


<span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
    <span class="n">filtered_sentence</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span> <span class="k">if</span> <span class="n">word</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stop_words</span><span class="p">]</span>
    <span class="n">filtered_sentences</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">filtered_sentence</span><span class="p">)</span>


<span class="c1"># Cetak kalimat-kalimat yang telah diproses</span>
<span class="k">for</span> <span class="n">filtered_sentence</span> <span class="ow">in</span> <span class="n">filtered_sentences</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">filtered_sentence</span><span class="p">)</span>

<span class="c1"># Tutup respons setelah digunakan</span>
<span class="n">response</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;jakarta&#39;, &#39;jaksa&#39;, &#39;penuntut&#39;, &#39;jpu&#39;, &#39;kejaksaan&#39;, &#39;agung&#39;, &#39;kejagung&#39;, &#39;ri&#39;, &#39;menuntut&#39;, &#39;account&#39;, &#39;director&#39;, &#39;of&#39;, &#39;integrated&#39;, &#39;account&#39;, &#39;departement&#39;, &#39;pt&#39;, &#39;huawei&#39;, &#39;tech&#39;, &#39;investment&#39;, &#39;mukti&#39;, &#39;ali&#39;, &#39;membayar&#39;, &#39;denda&#39;, &#39;rp&#39;, &#39;juta&#39;, &#39;subsider&#39;, &#39;pidana&#39;, &#39;kurungan&#39;, &#39;perkara&#39;, &#39;korupsi&#39;, &#39;bts&#39;, &#39;g&#39;, &#39;kementerian&#39;, &#39;komunikasi&#39;, &#39;informatika&#39;, &#39;kemenkominfo&#39;, &#39;.&#39;]
[&#39;menjatuhkan&#39;, &#39;pidana&#39;, &#39;terdakwa&#39;, &#39;mukti&#39;, &#39;ali&#39;, &#39;dikurangi&#39;, &#39;sepenuhnya&#39;, &#39;terdakwa&#39;, &#39;ditahan&#39;, &#39;perintah&#39;, &#39;terdakwa&#39;, &#39;penahanan&#39;, &#39;rutan&#39;, &#39;jaksa&#39;, &#39;persidangan&#39;, &#39;pengadilan&#39;, &#39;tindak&#39;, &#39;pidana&#39;, &#39;korupsi&#39;, &#39;tipikor&#39;, &#39;pengadilan&#39;, &#39;negeri&#39;, &#39;jakarta&#39;, &#39;pusat&#39;, &#39;senin&#39;, &#39;.&#39;]
[&#39;jaksa&#39;, &#39;terdakwa&#39;, &#39;mukti&#39;, &#39;ali&#39;, &#39;terbukti&#39;, &#39;sah&#39;, &#39;bersalah&#39;, &#39;hukum&#39;, &#39;tindak&#39;, &#39;pidana&#39;, &#39;korupsi&#39;, &#39;bts&#39;, &#39;g&#39;, &#39;kementerian&#39;, &#39;komunikasi&#39;, &#39;informatika&#39;, &#39;kemenkominfo&#39;, &#39;.&#39;]
[&#39;mukti&#39;, &#39;didakwa&#39;, &#39;melanggar&#39;, &#39;pasal&#39;, &#39;ayat&#39;, &#39;juncto&#39;, &#39;pasal&#39;, &#39;undangundang&#39;, &#39;nomor&#39;, &#39;pemberantasan&#39;, &#39;tindak&#39;, &#39;pidana&#39;, &#39;korupsi&#39;, &#39;diubah&#39;, &#39;uu&#39;, &#39;no&#39;, &#39;.&#39;]
[&#39;jo&#39;, &#39;.&#39;]
[&#39;pasal&#39;, &#39;ayat&#39;, &#39;kuhp&#39;, &#39;.&#39;]
[&#39;halhal&#39;, &#39;memberatkan&#39;, &#39;terdakwa&#39;, &#39;perbuatannya&#39;, &#39;mendukung&#39;, &#39;program&#39;, &#39;pemerintah&#39;, &#39;rangka&#39;, &#39;penyelenggaraan&#39;, &#39;negara&#39;, &#39;bersih&#39;, &#39;korupsi&#39;, &#39;kolusi&#39;, &#39;nepotisme&#39;, &#39;.&#39;]
[&#39;perbuatan&#39;, &#39;terdakwa&#39;, &#39;bersamasama&#39;, &#39;terdakwa&#39;, &#39;mengakibatkan&#39;, &#39;kerugian&#39;, &#39;keuangan&#39;, &#39;negara&#39;, &#39;rp&#39;, &#39;....&#39;, &#39;jaksa&#39;, &#39;.&#39;]
[&#39;halhal&#39;, &#39;meringankan&#39;, &#39;mukti&#39;, &#39;ali&#39;, &#39;terdakwa&#39;, &#39;dihukum&#39;, &#39;bersikap&#39;, &#39;sopan&#39;, &#39;persidangan&#39;, &#39;menikmati&#39;, &#39;hasil&#39;, &#39;tindak&#39;, &#39;pidana&#39;, &#39;korupsi&#39;, &#39;.&#39;]
[&#39;baca&#39;, &#39;irwan&#39;, &#39;hermawan&#39;, &#39;dituntut&#39;, &#39;penjara&#39;, &#39;terkait&#39;, &#39;korupsi&#39;, &#39;bts&#39;, &#39;g&#39;, &#39;baca&#39;, &#39;galumbang&#39;, &#39;menak&#39;, &#39;dituntut&#39;, &#39;penjara&#39;, &#39;bts&#39;, &#39;g&#39;, &#39;sidang&#39;, &#39;tuntutan&#39;, &#39;digelar&#39;, &#39;bersamaan&#39;, &#39;tuntutan&#39;, &#39;terdakwa&#39;, &#39;komisaris&#39;, &#39;pt&#39;, &#39;solitech&#39;, &#39;media&#39;, &#39;sinergy&#39;, &#39;irwan&#39;, &#39;hermawan&#39;, &#39;eks&#39;, &#39;direktur&#39;, &#39;utama&#39;, &#39;pt&#39;, &#39;mora&#39;, &#39;telematika&#39;, &#39;indonesia&#39;, &#39;galumbang&#39;, &#39;menak&#39;, &#39;simanjuntak&#39;, &#39;.&#39;]
[&#39;irwan&#39;, &#39;hermawan&#39;, &#39;dituntut&#39;, &#39;pidana&#39;, &#39;penjara&#39;, &#39;galumbang&#39;, &#39;menak&#39;, &#39;dituntut&#39;, &#39;.&#39;]
[&#39;terdakwa&#39;, &#39;diduga&#39;, &#39;tindak&#39;, &#39;pidana&#39;, &#39;korupsi&#39;, &#39;penyediaan&#39;, &#39;infrastruktur&#39;, &#39;base&#39;, &#39;transceiver&#39;, &#39;station&#39;, &#39;bts&#39;, &#39;g&#39;, &#39;infrastruktur&#39;, &#39;pendukung&#39;, &#39;paket&#39;, &#39;bakti&#39;, &#39;kemenkominfo&#39;, &#39;.&#39;]
[&#39;surat&#39;, &#39;dakwaan&#39;, &#39;keuntungan&#39;, &#39;proyek&#39;, &#39;pembangunan&#39;, &#39;mantan&#39;, &#39;menteri&#39;, &#39;kominfo&#39;, &#39;johnny&#39;, &#39;g.&#39;, &#39;plate&#39;, &#39;menerima&#39;, &#39;uang&#39;, &#39;rp&#39;, &#39;...&#39;, &#39;mantan&#39;, &#39;direktur&#39;, &#39;utama&#39;, &#39;bakti&#39;, &#39;kominfo&#39;, &#39;anang&#39;, &#39;achmad&#39;, &#39;latif&#39;, &#39;menerima&#39;, &#39;uang&#39;, &#39;rp&#39;, &#39;miliar&#39;, &#39;tenaga&#39;, &#39;ahli&#39;, &#39;human&#39;, &#39;development&#39;, &#39;universitas&#39;, &#39;indonesia&#39;, &#39;yohan&#39;, &#39;suryanto&#39;, &#39;menerima&#39;, &#39;rp&#39;, &#39;...&#39;, &#39;irwan&#39;, &#39;hermawan&#39;, &#39;komisaris&#39;, &#39;pt&#39;, &#39;solitechmedia&#39;, &#39;sinergy&#39;, &#39;menerima&#39;, &#39;rp&#39;, &#39;miliar&#39;, &#39;windi&#39;, &#39;purnama&#39;, &#39;direktur&#39;, &#39;pt&#39;, &#39;multimedia&#39;, &#39;berdikari&#39;, &#39;sejahtera&#39;, &#39;menerima&#39;, &#39;rp&#39;, &#39;juta&#39;, &#39;muhammad&#39;, &#39;yusrizki&#39;, &#39;direktur&#39;, &#39;pt&#39;, &#39;basis&#39;, &#39;utama&#39;, &#39;prima&#39;, &#39;menerima&#39;, &#39;rp&#39;, &#39;miliar&#39;, &#39;juta&#39;, &#39;dolar&#39;, &#39;as&#39;, &#39;konsorsium&#39;, &#39;fiberhome&#39;, &#39;pt&#39;, &#39;telkominfra&#39;, &#39;pt&#39;, &#39;multi&#39;, &#39;trans&#39;, &#39;data&#39;, &#39;pt&#39;, &#39;mtd&#39;, &#39;paket&#39;, &#39;menerima&#39;, &#39;rp&#39;, &#39;....&#39;, &#39;konsorsium&#39;, &#39;lintasarta&#39;, &#39;huawei&#39;, &#39;sei&#39;, &#39;paket&#39;, &#39;menerima&#39;, &#39;rp&#39;, &#39;....&#39;, &#39;konsorsium&#39;, &#39;ibs&#39;, &#39;zte&#39;, &#39;paket&#39;, &#39;rp&#39;, &#39;.....&#39;, &#39;pewarta&#39;, &#39;rivan&#39;, &#39;linggaeditor&#39;, &#39;d.dj&#39;, &#39;.&#39;]
[&#39;kliwantoro&#39;, &#39;copyright&#39;]
</pre></div>
</div>
</div>
</div>
</section>
<section id="tf-idf">
<h1><strong>TF-IDF</strong><a class="headerlink" href="#tf-idf" title="Permalink to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">tabulate</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.9.0)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tabulate</span> <span class="kn">import</span> <span class="n">tabulate</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>

<span class="c1"># Assuming filtered_sentences is a list of sentences after stopword removal</span>

<span class="c1"># Join the filtered sentences into a list of strings</span>
<span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">filtered_sentences</span><span class="p">]</span>

<span class="c1"># Create the TF-IDF vectorizer</span>
<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">()</span>

<span class="c1"># Fit and transform the corpus to get the TF-IDF matrix</span>
<span class="n">tfidf_matrix</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>

<span class="c1"># Get the feature names (words) from the vectorizer</span>
<span class="n">feature_names</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">()</span>

<span class="c1"># Convert the TF-IDF matrix to a Pandas DataFrame for better visualization</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">tfidf_matrix</span><span class="o">.</span><span class="n">toarray</span><span class="p">(),</span> <span class="n">columns</span><span class="o">=</span><span class="n">feature_names</span><span class="p">)</span>

<span class="c1"># Add a column for the sentences</span>
<span class="n">df</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;Kalimat&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">filtered_sentences</span><span class="p">])</span>

<span class="c1"># Add a column for the sentence numbers</span>
<span class="n">df</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;No&#39;</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">filtered_sentences</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>

<span class="c1"># Add a column for the count of terms in each sentence</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Term Count&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;Kalimat&#39;</span><span class="p">,</span> <span class="s1">&#39;No&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">gt</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Set the display options for Pandas to show all columns without truncation</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s2">&quot;display.max_columns&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

<span class="c1"># Print the DataFrame in a tabular format with borders</span>
<span class="n">table</span> <span class="o">=</span> <span class="n">tabulate</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="s1">&#39;keys&#39;</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s1">&#39;fancy_grid&#39;</span><span class="p">,</span> <span class="n">showindex</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>╒══════╤═════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╤═══════════╤═══════════╤══════════╤═══════════╤══════════╤═══════════╤═══════════╤══════════╤══════════╤═══════════╤═════════╤═══════════╤═════════════╤════════════╤═════════════╤═══════════════╤══════════╤════════════╤══════════╤═════════════╤═══════════╤═══════════╤══════════╤═══════════════╤═══════════════╤═══════════╤══════════╤═══════════╤═══════════╤═════════════╤════════════╤════════════╤═══════════╤════════════╤══════════╤═══════════╤═══════════╤══════════╤═════════════╤═════════════╤══════════╤══════════╤════════════╤═══════════╤══════════╤═══════════╤═══════════╤═════════════╤═══════════════╤═════════════════╤══════════════╤══════════════╤═══════════╤═══════════╤══════════╤══════╤═══════════╤══════════╤══════════╤══════════╤════════════╤═════════════╤════════════════╤═══════════════╤════════════╤════════════╤══════════════╤══════════════╤══════════╤═══════════╤═════════════╤══════════════╤══════════════╤═══════════╤═════════╤════════════╤═══════════╤════════════════╤══════════════╤══════════╤══════════╤═════════════╤════════════╤═══════════════╤══════════╤═════════════╤════════════╤═════════════════╤═════════════╤═══════════════╤═══════════╤════════════╤═══════════════╤══════════╤══════════╤═══════════╤════════════╤══════════╤═══════════╤══════════════╤══════════╤══════════╤═════════════╤══════════╤══════════╤══════════╤══════════╤══════════╤═══════════════╤═════════════════╤══════════════╤═════════════╤═════════════╤══════════════╤═══════════╤════════════╤══════════════╤═══════════════════╤═════════════╤════════════════╤════════════╤═══════════╤═══════════════╤═══════════╤══════════╤═══════════╤═══════════╤═══════════╤═══════════╤══════════╤═══════════╤══════════╤══════════╤══════════╤═══════════╤══════════╤══════════╤══════════╤═══════════╤═════════════╤══════════╤══════════════╤══════════╤═══════════════╤═══════════╤════════════╤═════════════════╤══════════╤═══════════╤════════════╤═══════════╤════════════╤══════════╤══════════════╤═══════════════╤═══════════╤════════════╤════════════╤═══════════╤══════════╤═══════════╤═══════════╤═══════════════╤════════════╤══════════╤════════════════╤═══════════════╤══════════╤══════════╤═══════════╤═══════════╤════════════╤═══════════╤══════════════╕
│   No │ Kalimat                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     │   account │    achmad │    agung │      ahli │      ali │     anang │        as │     ayat │     baca │     bakti │    base │     basis │   berdikari │   bersalah │   bersamaan │   bersamasama │   bersih │   bersikap │      bts │   copyright │   dakwaan │      data │    denda │   departement │   development │   didakwa │   diduga │   digelar │   dihukum │   dikurangi │   director │   direktur │   ditahan │   dituntut │   diubah │        dj │     dolar │      eks │   fiberhome │   galumbang │   halhal │    hasil │   hermawan │    huawei │    hukum │     human │       ibs │   indonesia │   informatika │   infrastruktur │   integrated │   investment │     irwan │   jakarta │    jaksa │   jo │    johnny │      jpu │   juncto │     juta │   kejagung │   kejaksaan │   kemenkominfo │   kementerian │   kerugian │   keuangan │   keuntungan │   kliwantoro │   kolusi │   kominfo │   komisaris │   komunikasi │   konsorsium │   korupsi │    kuhp │   kurungan │     latif │   linggaeditor │   lintasarta │   mantan │    media │   melanggar │   membayar │   memberatkan │    menak │   mendukung │   menerima │   mengakibatkan │   menikmati │   menjatuhkan │   menteri │   menuntut │   meringankan │   miliar │     mora │       mtd │   muhammad │    mukti │     multi │   multimedia │   negara │   negeri │   nepotisme │       no │    nomor │       of │    paket │    pasal │   pembangunan │   pemberantasan │   pemerintah │   penahanan │   pendukung │   pengadilan │   penjara │   penuntut │   penyediaan │   penyelenggaraan │   perbuatan │   perbuatannya │   perintah │   perkara │   persidangan │   pewarta │   pidana │     plate │     prima │   program │    proyek │       pt │   purnama │    pusat │   rangka │       ri │     rivan │       rp │    rutan │      sah │       sei │   sejahtera │    senin │   sepenuhnya │   sidang │   simanjuntak │   sinergy │   solitech │   solitechmedia │    sopan │   station │   subsider │     surat │   suryanto │     tech │   telematika │   telkominfra │    tenaga │   terbukti │   terdakwa │   terkait │   tindak │   tipikor │     trans │   transceiver │   tuntutan │     uang │   undangundang │   universitas │    utama │       uu │     windi │     yohan │   yusrizki │       zte │   Term Count │
╞══════╪═════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╪═══════════╪═══════════╪══════════╪═══════════╪══════════╪═══════════╪═══════════╪══════════╪══════════╪═══════════╪═════════╪═══════════╪═════════════╪════════════╪═════════════╪═══════════════╪══════════╪════════════╪══════════╪═════════════╪═══════════╪═══════════╪══════════╪═══════════════╪═══════════════╪═══════════╪══════════╪═══════════╪═══════════╪═════════════╪════════════╪════════════╪═══════════╪════════════╪══════════╪═══════════╪═══════════╪══════════╪═════════════╪═════════════╪══════════╪══════════╪════════════╪═══════════╪══════════╪═══════════╪═══════════╪═════════════╪═══════════════╪═════════════════╪══════════════╪══════════════╪═══════════╪═══════════╪══════════╪══════╪═══════════╪══════════╪══════════╪══════════╪════════════╪═════════════╪════════════════╪═══════════════╪════════════╪════════════╪══════════════╪══════════════╪══════════╪═══════════╪═════════════╪══════════════╪══════════════╪═══════════╪═════════╪════════════╪═══════════╪════════════════╪══════════════╪══════════╪══════════╪═════════════╪════════════╪═══════════════╪══════════╪═════════════╪════════════╪═════════════════╪═════════════╪═══════════════╪═══════════╪════════════╪═══════════════╪══════════╪══════════╪═══════════╪════════════╪══════════╪═══════════╪══════════════╪══════════╪══════════╪═════════════╪══════════╪══════════╪══════════╪══════════╪══════════╪═══════════════╪═════════════════╪══════════════╪═════════════╪═════════════╪══════════════╪═══════════╪════════════╪══════════════╪═══════════════════╪═════════════╪════════════════╪════════════╪═══════════╪═══════════════╪═══════════╪══════════╪═══════════╪═══════════╪═══════════╪═══════════╪══════════╪═══════════╪══════════╪══════════╪══════════╪═══════════╪══════════╪══════════╪══════════╪═══════════╪═════════════╪══════════╪══════════════╪══════════╪═══════════════╪═══════════╪════════════╪═════════════════╪══════════╪═══════════╪════════════╪═══════════╪════════════╪══════════╪══════════════╪═══════════════╪═══════════╪════════════╪════════════╪═══════════╪══════════╪═══════════╪═══════════╪═══════════════╪════════════╪══════════╪════════════════╪═══════════════╪══════════╪══════════╪═══════════╪═══════════╪════════════╪═══════════╪══════════════╡
│    1 │ jakarta jaksa penuntut jpu kejaksaan agung kejagung ri menuntut account director of integrated account departement pt huawei tech investment mukti ali membayar denda rp juta subsider pidana kurungan perkara korupsi bts g kementerian komunikasi informatika kemenkominfo .                                                                                                                                                                                                                                                                                                                                                                                                                                              │  0.361113 │ 0         │ 0.180556 │ 0         │ 0.125682 │ 0         │ 0         │ 0        │ 0        │ 0         │ 0       │ 0         │   0         │   0        │    0        │      0        │ 0        │   0        │ 0.125682 │    0        │ 0         │ 0         │ 0.180556 │      0.180556 │     0         │  0        │  0       │  0        │  0        │    0        │   0.180556 │   0        │  0        │   0        │ 0        │ 0         │ 0         │ 0        │   0         │    0        │ 0        │ 0        │  0         │ 0.156274  │ 0        │ 0         │ 0         │   0         │      0.156274 │        0        │     0.180556 │     0.180556 │ 0         │  0.156274 │ 0.125682 │    0 │ 0         │ 0.180556 │ 0        │ 0.156274 │   0.180556 │    0.180556 │       0.139045 │      0.156274 │   0        │   0        │    0         │     0        │ 0        │  0        │   0         │     0.156274 │     0        │ 0.0904802 │ 0       │   0.180556 │ 0         │      0         │    0         │ 0        │ 0        │    0        │   0.180556 │      0        │ 0        │    0        │   0        │        0        │    0        │      0        │ 0         │   0.180556 │      0        │ 0        │ 0        │ 0         │  0         │ 0.114763 │ 0         │    0         │ 0        │ 0        │    0        │ 0        │ 0        │ 0.180556 │ 0        │ 0        │     0         │        0        │     0        │    0        │     0       │     0        │  0        │   0.180556 │      0       │          0        │    0        │       0        │   0        │  0.180556 │      0        │ 0         │ 0.097534 │ 0         │ 0         │  0        │ 0         │ 0.139045 │ 0         │ 0        │ 0        │ 0.180556 │ 0         │ 0.139045 │ 0        │ 0        │ 0         │   0         │ 0        │     0        │ 0        │      0        │ 0         │   0        │       0         │ 0        │   0       │   0.180556 │ 0         │  0         │ 0.180556 │     0        │     0         │ 0         │   0        │  0         │  0        │ 0        │  0        │ 0         │       0       │   0        │ 0        │       0        │     0         │ 0        │ 0        │ 0         │ 0         │  0         │ 0         │           34 │
├──────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼───────────┼───────────┼──────────┼───────────┼──────────┼───────────┼───────────┼──────────┼──────────┼───────────┼─────────┼───────────┼─────────────┼────────────┼─────────────┼───────────────┼──────────┼────────────┼──────────┼─────────────┼───────────┼───────────┼──────────┼───────────────┼───────────────┼───────────┼──────────┼───────────┼───────────┼─────────────┼────────────┼────────────┼───────────┼────────────┼──────────┼───────────┼───────────┼──────────┼─────────────┼─────────────┼──────────┼──────────┼────────────┼───────────┼──────────┼───────────┼───────────┼─────────────┼───────────────┼─────────────────┼──────────────┼──────────────┼───────────┼───────────┼──────────┼──────┼───────────┼──────────┼──────────┼──────────┼────────────┼─────────────┼────────────────┼───────────────┼────────────┼────────────┼──────────────┼──────────────┼──────────┼───────────┼─────────────┼──────────────┼──────────────┼───────────┼─────────┼────────────┼───────────┼────────────────┼──────────────┼──────────┼──────────┼─────────────┼────────────┼───────────────┼──────────┼─────────────┼────────────┼─────────────────┼─────────────┼───────────────┼───────────┼────────────┼───────────────┼──────────┼──────────┼───────────┼────────────┼──────────┼───────────┼──────────────┼──────────┼──────────┼─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼───────────────┼─────────────────┼──────────────┼─────────────┼─────────────┼──────────────┼───────────┼────────────┼──────────────┼───────────────────┼─────────────┼────────────────┼────────────┼───────────┼───────────────┼───────────┼──────────┼───────────┼───────────┼───────────┼───────────┼──────────┼───────────┼──────────┼──────────┼──────────┼───────────┼──────────┼──────────┼──────────┼───────────┼─────────────┼──────────┼──────────────┼──────────┼───────────────┼───────────┼────────────┼─────────────────┼──────────┼───────────┼────────────┼───────────┼────────────┼──────────┼──────────────┼───────────────┼───────────┼────────────┼────────────┼───────────┼──────────┼───────────┼───────────┼───────────────┼────────────┼──────────┼────────────────┼───────────────┼──────────┼──────────┼───────────┼───────────┼────────────┼───────────┼──────────────┤
│    2 │ menjatuhkan pidana terdakwa mukti ali dikurangi sepenuhnya terdakwa ditahan perintah terdakwa penahanan rutan jaksa persidangan pengadilan tindak pidana korupsi tipikor pengadilan negeri jakarta pusat senin .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            │  0        │ 0         │ 0        │ 0         │ 0.147338 │ 0         │ 0         │ 0        │ 0        │ 0         │ 0       │ 0         │   0         │   0        │    0        │      0        │ 0        │   0        │ 0        │    0        │ 0         │ 0         │ 0        │      0        │     0         │  0        │  0       │  0        │  0        │    0.211668 │   0        │   0        │  0.211668 │   0        │ 0        │ 0         │ 0         │ 0        │   0         │    0        │ 0        │ 0        │  0         │ 0         │ 0        │ 0         │ 0         │   0         │      0        │        0        │     0        │     0        │ 0         │  0.183201 │ 0.147338 │    0 │ 0         │ 0        │ 0        │ 0        │   0        │    0        │       0        │      0        │   0        │   0        │    0         │     0        │ 0        │  0        │   0         │     0        │     0        │ 0.106071  │ 0       │   0        │ 0         │      0         │    0         │ 0        │ 0        │    0        │   0        │      0        │ 0        │    0        │   0        │        0        │    0        │      0.211668 │ 0         │   0        │      0        │ 0        │ 0        │ 0         │  0         │ 0.134537 │ 0         │    0         │ 0        │ 0.211668 │    0        │ 0        │ 0        │ 0        │ 0        │ 0        │     0         │        0        │     0        │    0.211668 │     0       │     0.423336 │  0        │   0        │      0       │          0        │    0        │       0        │   0.211668 │  0        │      0.183201 │ 0         │ 0.22868  │ 0         │ 0         │  0        │ 0         │ 0        │ 0         │ 0.211668 │ 0        │ 0        │ 0         │ 0        │ 0.211668 │ 0        │ 0         │   0         │ 0.211668 │     0.211668 │ 0        │      0        │ 0         │   0        │       0         │ 0        │   0       │   0        │ 0         │  0         │ 0        │     0        │     0         │ 0         │   0        │  0.34302   │  0        │ 0.134537 │  0.211668 │ 0         │       0       │   0        │ 0        │       0        │     0         │ 0        │ 0        │ 0         │ 0         │  0         │ 0         │           21 │
├──────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼───────────┼───────────┼──────────┼───────────┼──────────┼───────────┼───────────┼──────────┼──────────┼───────────┼─────────┼───────────┼─────────────┼────────────┼─────────────┼───────────────┼──────────┼────────────┼──────────┼─────────────┼───────────┼───────────┼──────────┼───────────────┼───────────────┼───────────┼──────────┼───────────┼───────────┼─────────────┼────────────┼────────────┼───────────┼────────────┼──────────┼───────────┼───────────┼──────────┼─────────────┼─────────────┼──────────┼──────────┼────────────┼───────────┼──────────┼───────────┼───────────┼─────────────┼───────────────┼─────────────────┼──────────────┼──────────────┼───────────┼───────────┼──────────┼──────┼───────────┼──────────┼──────────┼──────────┼────────────┼─────────────┼────────────────┼───────────────┼────────────┼────────────┼──────────────┼──────────────┼──────────┼───────────┼─────────────┼──────────────┼──────────────┼───────────┼─────────┼────────────┼───────────┼────────────────┼──────────────┼──────────┼──────────┼─────────────┼────────────┼───────────────┼──────────┼─────────────┼────────────┼─────────────────┼─────────────┼───────────────┼───────────┼────────────┼───────────────┼──────────┼──────────┼───────────┼────────────┼──────────┼───────────┼──────────────┼──────────┼──────────┼─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼───────────────┼─────────────────┼──────────────┼─────────────┼─────────────┼──────────────┼───────────┼────────────┼──────────────┼───────────────────┼─────────────┼────────────────┼────────────┼───────────┼───────────────┼───────────┼──────────┼───────────┼───────────┼───────────┼───────────┼──────────┼───────────┼──────────┼──────────┼──────────┼───────────┼──────────┼──────────┼──────────┼───────────┼─────────────┼──────────┼──────────────┼──────────┼───────────────┼───────────┼────────────┼─────────────────┼──────────┼───────────┼────────────┼───────────┼────────────┼──────────┼──────────────┼───────────────┼───────────┼────────────┼────────────┼───────────┼──────────┼───────────┼───────────┼───────────────┼────────────┼──────────┼────────────────┼───────────────┼──────────┼──────────┼───────────┼───────────┼────────────┼───────────┼──────────────┤
│    3 │ jaksa terdakwa mukti ali terbukti sah bersalah hukum tindak pidana korupsi bts g kementerian komunikasi informatika kemenkominfo .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          │  0        │ 0         │ 0        │ 0         │ 0.22082  │ 0         │ 0         │ 0        │ 0        │ 0         │ 0       │ 0         │   0         │   0.317234 │    0        │      0        │ 0        │   0        │ 0.22082  │    0        │ 0         │ 0         │ 0        │      0        │     0         │  0        │  0       │  0        │  0        │    0        │   0        │   0        │  0        │   0        │ 0        │ 0         │ 0         │ 0        │   0         │    0        │ 0        │ 0        │  0         │ 0         │ 0.317234 │ 0         │ 0         │   0         │      0.27457  │        0        │     0        │     0        │ 0         │  0        │ 0.22082  │    0 │ 0         │ 0        │ 0        │ 0        │   0        │    0        │       0.2443   │      0.27457  │   0        │   0        │    0         │     0        │ 0        │  0        │   0         │     0.27457  │     0        │ 0.158972  │ 0       │   0        │ 0         │      0         │    0         │ 0        │ 0        │    0        │   0        │      0        │ 0        │    0        │   0        │        0        │    0        │      0        │ 0         │   0        │      0        │ 0        │ 0        │ 0         │  0         │ 0.201636 │ 0         │    0         │ 0        │ 0        │    0        │ 0        │ 0        │ 0        │ 0        │ 0        │     0         │        0        │     0        │    0        │     0       │     0        │  0        │   0        │      0       │          0        │    0        │       0        │   0        │  0        │      0        │ 0         │ 0.171365 │ 0         │ 0         │  0        │ 0         │ 0        │ 0         │ 0        │ 0        │ 0        │ 0         │ 0        │ 0        │ 0.317234 │ 0         │   0         │ 0        │     0        │ 0        │      0        │ 0         │   0        │       0         │ 0        │   0       │   0        │ 0         │  0         │ 0        │     0        │     0         │ 0         │   0.317234 │  0.171365  │  0        │ 0.201636 │  0        │ 0         │       0       │   0        │ 0        │       0        │     0         │ 0        │ 0        │ 0         │ 0         │  0         │ 0         │           16 │
├──────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼───────────┼───────────┼──────────┼───────────┼──────────┼───────────┼───────────┼──────────┼──────────┼───────────┼─────────┼───────────┼─────────────┼────────────┼─────────────┼───────────────┼──────────┼────────────┼──────────┼─────────────┼───────────┼───────────┼──────────┼───────────────┼───────────────┼───────────┼──────────┼───────────┼───────────┼─────────────┼────────────┼────────────┼───────────┼────────────┼──────────┼───────────┼───────────┼──────────┼─────────────┼─────────────┼──────────┼──────────┼────────────┼───────────┼──────────┼───────────┼───────────┼─────────────┼───────────────┼─────────────────┼──────────────┼──────────────┼───────────┼───────────┼──────────┼──────┼───────────┼──────────┼──────────┼──────────┼────────────┼─────────────┼────────────────┼───────────────┼────────────┼────────────┼──────────────┼──────────────┼──────────┼───────────┼─────────────┼──────────────┼──────────────┼───────────┼─────────┼────────────┼───────────┼────────────────┼──────────────┼──────────┼──────────┼─────────────┼────────────┼───────────────┼──────────┼─────────────┼────────────┼─────────────────┼─────────────┼───────────────┼───────────┼────────────┼───────────────┼──────────┼──────────┼───────────┼────────────┼──────────┼───────────┼──────────────┼──────────┼──────────┼─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼───────────────┼─────────────────┼──────────────┼─────────────┼─────────────┼──────────────┼───────────┼────────────┼──────────────┼───────────────────┼─────────────┼────────────────┼────────────┼───────────┼───────────────┼───────────┼──────────┼───────────┼───────────┼───────────┼───────────┼──────────┼───────────┼──────────┼──────────┼──────────┼───────────┼──────────┼──────────┼──────────┼───────────┼─────────────┼──────────┼──────────────┼──────────┼───────────────┼───────────┼────────────┼─────────────────┼──────────┼───────────┼────────────┼───────────┼────────────┼──────────┼──────────────┼───────────────┼───────────┼────────────┼────────────┼───────────┼──────────┼───────────┼───────────┼───────────────┼────────────┼──────────┼────────────────┼───────────────┼──────────┼──────────┼───────────┼───────────┼────────────┼───────────┼──────────────┤
│    4 │ mukti didakwa melanggar pasal ayat juncto pasal undangundang nomor pemberantasan tindak pidana korupsi diubah uu no .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       │  0        │ 0         │ 0        │ 0         │ 0        │ 0         │ 0         │ 0.230525 │ 0        │ 0         │ 0       │ 0         │   0         │   0        │    0        │      0        │ 0        │   0        │ 0        │    0        │ 0         │ 0         │ 0        │      0        │     0         │  0.266345 │  0       │  0        │  0        │    0        │   0        │   0        │  0        │   0        │ 0.266345 │ 0         │ 0         │ 0        │   0         │    0        │ 0        │ 0        │  0         │ 0         │ 0        │ 0         │ 0         │   0         │      0        │        0        │     0        │     0        │ 0         │  0        │ 0        │    0 │ 0         │ 0        │ 0.266345 │ 0        │   0        │    0        │       0        │      0        │   0        │   0        │    0         │     0        │ 0        │  0        │   0         │     0        │     0        │ 0.133471  │ 0       │   0        │ 0         │      0         │    0         │ 0        │ 0        │    0.266345 │   0        │      0        │ 0        │    0        │   0        │        0        │    0        │      0        │ 0         │   0        │      0        │ 0        │ 0        │ 0         │  0         │ 0.169291 │ 0         │    0         │ 0        │ 0        │    0        │ 0.266345 │ 0.266345 │ 0        │ 0        │ 0.46105  │     0         │        0.266345 │     0        │    0        │     0       │     0        │  0        │   0        │      0       │          0        │    0        │       0        │   0        │  0        │      0        │ 0         │ 0.143876 │ 0         │ 0         │  0        │ 0         │ 0        │ 0         │ 0        │ 0        │ 0        │ 0         │ 0        │ 0        │ 0        │ 0         │   0         │ 0        │     0        │ 0        │      0        │ 0         │   0        │       0         │ 0        │   0       │   0        │ 0         │  0         │ 0        │     0        │     0         │ 0         │   0        │  0         │  0        │ 0.169291 │  0        │ 0         │       0       │   0        │ 0        │       0.266345 │     0         │ 0        │ 0.266345 │ 0         │ 0         │  0         │ 0         │           15 │
├──────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼───────────┼───────────┼──────────┼───────────┼──────────┼───────────┼───────────┼──────────┼──────────┼───────────┼─────────┼───────────┼─────────────┼────────────┼─────────────┼───────────────┼──────────┼────────────┼──────────┼─────────────┼───────────┼───────────┼──────────┼───────────────┼───────────────┼───────────┼──────────┼───────────┼───────────┼─────────────┼────────────┼────────────┼───────────┼────────────┼──────────┼───────────┼───────────┼──────────┼─────────────┼─────────────┼──────────┼──────────┼────────────┼───────────┼──────────┼───────────┼───────────┼─────────────┼───────────────┼─────────────────┼──────────────┼──────────────┼───────────┼───────────┼──────────┼──────┼───────────┼──────────┼──────────┼──────────┼────────────┼─────────────┼────────────────┼───────────────┼────────────┼────────────┼──────────────┼──────────────┼──────────┼───────────┼─────────────┼──────────────┼──────────────┼───────────┼─────────┼────────────┼───────────┼────────────────┼──────────────┼──────────┼──────────┼─────────────┼────────────┼───────────────┼──────────┼─────────────┼────────────┼─────────────────┼─────────────┼───────────────┼───────────┼────────────┼───────────────┼──────────┼──────────┼───────────┼────────────┼──────────┼───────────┼──────────────┼──────────┼──────────┼─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼───────────────┼─────────────────┼──────────────┼─────────────┼─────────────┼──────────────┼───────────┼────────────┼──────────────┼───────────────────┼─────────────┼────────────────┼────────────┼───────────┼───────────────┼───────────┼──────────┼───────────┼───────────┼───────────┼───────────┼──────────┼───────────┼──────────┼──────────┼──────────┼───────────┼──────────┼──────────┼──────────┼───────────┼─────────────┼──────────┼──────────────┼──────────┼───────────────┼───────────┼────────────┼─────────────────┼──────────┼───────────┼────────────┼───────────┼────────────┼──────────┼──────────────┼───────────────┼───────────┼────────────┼────────────┼───────────┼──────────┼───────────┼───────────┼───────────────┼────────────┼──────────┼────────────────┼───────────────┼──────────┼──────────┼───────────┼───────────┼────────────┼───────────┼──────────────┤
│    5 │ jo .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        │  0        │ 0         │ 0        │ 0         │ 0        │ 0         │ 0         │ 0        │ 0        │ 0         │ 0       │ 0         │   0         │   0        │    0        │      0        │ 0        │   0        │ 0        │    0        │ 0         │ 0         │ 0        │      0        │     0         │  0        │  0       │  0        │  0        │    0        │   0        │   0        │  0        │   0        │ 0        │ 0         │ 0         │ 0        │   0         │    0        │ 0        │ 0        │  0         │ 0         │ 0        │ 0         │ 0         │   0         │      0        │        0        │     0        │     0        │ 0         │  0        │ 0        │    1 │ 0         │ 0        │ 0        │ 0        │   0        │    0        │       0        │      0        │   0        │   0        │    0         │     0        │ 0        │  0        │   0         │     0        │     0        │ 0         │ 0       │   0        │ 0         │      0         │    0         │ 0        │ 0        │    0        │   0        │      0        │ 0        │    0        │   0        │        0        │    0        │      0        │ 0         │   0        │      0        │ 0        │ 0        │ 0         │  0         │ 0        │ 0         │    0         │ 0        │ 0        │    0        │ 0        │ 0        │ 0        │ 0        │ 0        │     0         │        0        │     0        │    0        │     0       │     0        │  0        │   0        │      0       │          0        │    0        │       0        │   0        │  0        │      0        │ 0         │ 0        │ 0         │ 0         │  0        │ 0         │ 0        │ 0         │ 0        │ 0        │ 0        │ 0         │ 0        │ 0        │ 0        │ 0         │   0         │ 0        │     0        │ 0        │      0        │ 0         │   0        │       0         │ 0        │   0       │   0        │ 0         │  0         │ 0        │     0        │     0         │ 0         │   0        │  0         │  0        │ 0        │  0        │ 0         │       0       │   0        │ 0        │       0        │     0         │ 0        │ 0        │ 0         │ 0         │  0         │ 0         │            1 │
├──────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼───────────┼───────────┼──────────┼───────────┼──────────┼───────────┼───────────┼──────────┼──────────┼───────────┼─────────┼───────────┼─────────────┼────────────┼─────────────┼───────────────┼──────────┼────────────┼──────────┼─────────────┼───────────┼───────────┼──────────┼───────────────┼───────────────┼───────────┼──────────┼───────────┼───────────┼─────────────┼────────────┼────────────┼───────────┼────────────┼──────────┼───────────┼───────────┼──────────┼─────────────┼─────────────┼──────────┼──────────┼────────────┼───────────┼──────────┼───────────┼───────────┼─────────────┼───────────────┼─────────────────┼──────────────┼──────────────┼───────────┼───────────┼──────────┼──────┼───────────┼──────────┼──────────┼──────────┼────────────┼─────────────┼────────────────┼───────────────┼────────────┼────────────┼──────────────┼──────────────┼──────────┼───────────┼─────────────┼──────────────┼──────────────┼───────────┼─────────┼────────────┼───────────┼────────────────┼──────────────┼──────────┼──────────┼─────────────┼────────────┼───────────────┼──────────┼─────────────┼────────────┼─────────────────┼─────────────┼───────────────┼───────────┼────────────┼───────────────┼──────────┼──────────┼───────────┼────────────┼──────────┼───────────┼──────────────┼──────────┼──────────┼─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼───────────────┼─────────────────┼──────────────┼─────────────┼─────────────┼──────────────┼───────────┼────────────┼──────────────┼───────────────────┼─────────────┼────────────────┼────────────┼───────────┼───────────────┼───────────┼──────────┼───────────┼───────────┼───────────┼───────────┼──────────┼───────────┼──────────┼──────────┼──────────┼───────────┼──────────┼──────────┼──────────┼───────────┼─────────────┼──────────┼──────────────┼──────────┼───────────────┼───────────┼────────────┼─────────────────┼──────────┼───────────┼────────────┼───────────┼────────────┼──────────┼──────────────┼───────────────┼───────────┼────────────┼────────────┼───────────┼──────────┼───────────┼───────────┼───────────────┼────────────┼──────────┼────────────────┼───────────────┼──────────┼──────────┼───────────┼───────────┼────────────┼───────────┼──────────────┤
│    6 │ pasal ayat kuhp .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           │  0        │ 0         │ 0        │ 0         │ 0        │ 0         │ 0         │ 0.547593 │ 0        │ 0         │ 0       │ 0         │   0         │   0        │    0        │      0        │ 0        │   0        │ 0        │    0        │ 0         │ 0         │ 0        │      0        │     0         │  0        │  0       │  0        │  0        │    0        │   0        │   0        │  0        │   0        │ 0        │ 0         │ 0         │ 0        │   0         │    0        │ 0        │ 0        │  0         │ 0         │ 0        │ 0         │ 0         │   0         │      0        │        0        │     0        │     0        │ 0         │  0        │ 0        │    0 │ 0         │ 0        │ 0        │ 0        │   0        │    0        │       0        │      0        │   0        │   0        │    0         │     0        │ 0        │  0        │   0         │     0        │     0        │ 0         │ 0.63268 │   0        │ 0         │      0         │    0         │ 0        │ 0        │    0        │   0        │      0        │ 0        │    0        │   0        │        0        │    0        │      0        │ 0         │   0        │      0        │ 0        │ 0        │ 0         │  0         │ 0        │ 0         │    0         │ 0        │ 0        │    0        │ 0        │ 0        │ 0        │ 0        │ 0.547593 │     0         │        0        │     0        │    0        │     0       │     0        │  0        │   0        │      0       │          0        │    0        │       0        │   0        │  0        │      0        │ 0         │ 0        │ 0         │ 0         │  0        │ 0         │ 0        │ 0         │ 0        │ 0        │ 0        │ 0         │ 0        │ 0        │ 0        │ 0         │   0         │ 0        │     0        │ 0        │      0        │ 0         │   0        │       0         │ 0        │   0       │   0        │ 0         │  0         │ 0        │     0        │     0         │ 0         │   0        │  0         │  0        │ 0        │  0        │ 0         │       0       │   0        │ 0        │       0        │     0         │ 0        │ 0        │ 0         │ 0         │  0         │ 0         │            3 │
├──────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼───────────┼───────────┼──────────┼───────────┼──────────┼───────────┼───────────┼──────────┼──────────┼───────────┼─────────┼───────────┼─────────────┼────────────┼─────────────┼───────────────┼──────────┼────────────┼──────────┼─────────────┼───────────┼───────────┼──────────┼───────────────┼───────────────┼───────────┼──────────┼───────────┼───────────┼─────────────┼────────────┼────────────┼───────────┼────────────┼──────────┼───────────┼───────────┼──────────┼─────────────┼─────────────┼──────────┼──────────┼────────────┼───────────┼──────────┼───────────┼───────────┼─────────────┼───────────────┼─────────────────┼──────────────┼──────────────┼───────────┼───────────┼──────────┼──────┼───────────┼──────────┼──────────┼──────────┼────────────┼─────────────┼────────────────┼───────────────┼────────────┼────────────┼──────────────┼──────────────┼──────────┼───────────┼─────────────┼──────────────┼──────────────┼───────────┼─────────┼────────────┼───────────┼────────────────┼──────────────┼──────────┼──────────┼─────────────┼────────────┼───────────────┼──────────┼─────────────┼────────────┼─────────────────┼─────────────┼───────────────┼───────────┼────────────┼───────────────┼──────────┼──────────┼───────────┼────────────┼──────────┼───────────┼──────────────┼──────────┼──────────┼─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼───────────────┼─────────────────┼──────────────┼─────────────┼─────────────┼──────────────┼───────────┼────────────┼──────────────┼───────────────────┼─────────────┼────────────────┼────────────┼───────────┼───────────────┼───────────┼──────────┼───────────┼───────────┼───────────┼───────────┼──────────┼───────────┼──────────┼──────────┼──────────┼───────────┼──────────┼──────────┼──────────┼───────────┼─────────────┼──────────┼──────────────┼──────────┼───────────────┼───────────┼────────────┼─────────────────┼──────────┼───────────┼────────────┼───────────┼────────────┼──────────┼──────────────┼───────────────┼───────────┼────────────┼────────────┼───────────┼──────────┼───────────┼───────────┼───────────────┼────────────┼──────────┼────────────────┼───────────────┼──────────┼──────────┼───────────┼───────────┼────────────┼───────────┼──────────────┤
│    7 │ halhal memberatkan terdakwa perbuatannya mendukung program pemerintah rangka penyelenggaraan negara bersih korupsi kolusi nepotisme .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       │  0        │ 0         │ 0        │ 0         │ 0        │ 0         │ 0         │ 0        │ 0        │ 0         │ 0       │ 0         │   0         │   0        │    0        │      0        │ 0.288181 │   0        │ 0        │    0        │ 0         │ 0         │ 0        │      0        │     0         │  0        │  0       │  0        │  0        │    0        │   0        │   0        │  0        │   0        │ 0        │ 0         │ 0         │ 0        │   0         │    0        │ 0.249425 │ 0        │  0         │ 0         │ 0        │ 0         │ 0         │   0         │      0        │        0        │     0        │     0        │ 0         │  0        │ 0        │    0 │ 0         │ 0        │ 0        │ 0        │   0        │    0        │       0        │      0        │   0        │   0        │    0         │     0        │ 0.288181 │  0        │   0         │     0        │     0        │ 0.144413  │ 0       │   0        │ 0         │      0         │    0         │ 0        │ 0        │    0        │   0        │      0.288181 │ 0        │    0.288181 │   0        │        0        │    0        │      0        │ 0         │   0        │      0        │ 0        │ 0        │ 0         │  0         │ 0        │ 0         │    0         │ 0.249425 │ 0        │    0.288181 │ 0        │ 0        │ 0        │ 0        │ 0        │     0         │        0        │     0.288181 │    0        │     0       │     0        │  0        │   0        │      0       │          0.288181 │    0        │       0.288181 │   0        │  0        │      0        │ 0         │ 0        │ 0         │ 0         │  0.288181 │ 0         │ 0        │ 0         │ 0        │ 0.288181 │ 0        │ 0         │ 0        │ 0        │ 0        │ 0         │   0         │ 0        │     0        │ 0        │      0        │ 0         │   0        │       0         │ 0        │   0       │   0        │ 0         │  0         │ 0        │     0        │     0         │ 0         │   0        │  0.155672  │  0        │ 0        │  0        │ 0         │       0       │   0        │ 0        │       0        │     0         │ 0        │ 0        │ 0         │ 0         │  0         │ 0         │           14 │
├──────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼───────────┼───────────┼──────────┼───────────┼──────────┼───────────┼───────────┼──────────┼──────────┼───────────┼─────────┼───────────┼─────────────┼────────────┼─────────────┼───────────────┼──────────┼────────────┼──────────┼─────────────┼───────────┼───────────┼──────────┼───────────────┼───────────────┼───────────┼──────────┼───────────┼───────────┼─────────────┼────────────┼────────────┼───────────┼────────────┼──────────┼───────────┼───────────┼──────────┼─────────────┼─────────────┼──────────┼──────────┼────────────┼───────────┼──────────┼───────────┼───────────┼─────────────┼───────────────┼─────────────────┼──────────────┼──────────────┼───────────┼───────────┼──────────┼──────┼───────────┼──────────┼──────────┼──────────┼────────────┼─────────────┼────────────────┼───────────────┼────────────┼────────────┼──────────────┼──────────────┼──────────┼───────────┼─────────────┼──────────────┼──────────────┼───────────┼─────────┼────────────┼───────────┼────────────────┼──────────────┼──────────┼──────────┼─────────────┼────────────┼───────────────┼──────────┼─────────────┼────────────┼─────────────────┼─────────────┼───────────────┼───────────┼────────────┼───────────────┼──────────┼──────────┼───────────┼────────────┼──────────┼───────────┼──────────────┼──────────┼──────────┼─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼───────────────┼─────────────────┼──────────────┼─────────────┼─────────────┼──────────────┼───────────┼────────────┼──────────────┼───────────────────┼─────────────┼────────────────┼────────────┼───────────┼───────────────┼───────────┼──────────┼───────────┼───────────┼───────────┼───────────┼──────────┼───────────┼──────────┼──────────┼──────────┼───────────┼──────────┼──────────┼──────────┼───────────┼─────────────┼──────────┼──────────────┼──────────┼───────────────┼───────────┼────────────┼─────────────────┼──────────┼───────────┼────────────┼───────────┼────────────┼──────────┼──────────────┼───────────────┼───────────┼────────────┼────────────┼───────────┼──────────┼───────────┼───────────┼───────────────┼────────────┼──────────┼────────────────┼───────────────┼──────────┼──────────┼───────────┼───────────┼────────────┼───────────┼──────────────┤
│    8 │ perbuatan terdakwa bersamasama terdakwa mengakibatkan kerugian keuangan negara rp .... jaksa .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              │  0        │ 0         │ 0        │ 0         │ 0        │ 0         │ 0         │ 0        │ 0        │ 0         │ 0       │ 0         │   0         │   0        │    0        │      0.353689 │ 0        │   0        │ 0        │    0        │ 0         │ 0         │ 0        │      0        │     0         │  0        │  0       │  0        │  0        │    0        │   0        │   0        │  0        │   0        │ 0        │ 0         │ 0         │ 0        │   0         │    0        │ 0        │ 0        │  0         │ 0         │ 0        │ 0         │ 0         │   0         │      0        │        0        │     0        │     0        │ 0         │  0        │ 0.246195 │    0 │ 0         │ 0        │ 0        │ 0        │   0        │    0        │       0        │      0        │   0.353689 │   0.353689 │    0         │     0        │ 0        │  0        │   0         │     0        │     0        │ 0         │ 0       │   0        │ 0         │      0         │    0         │ 0        │ 0        │    0        │   0        │      0        │ 0        │    0        │   0        │        0.353689 │    0        │      0        │ 0         │   0        │      0        │ 0        │ 0        │ 0         │  0         │ 0        │ 0         │    0         │ 0.306122 │ 0        │    0        │ 0        │ 0        │ 0        │ 0        │ 0        │     0         │        0        │     0        │    0        │     0       │     0        │  0        │   0        │      0       │          0        │    0.353689 │       0        │   0        │  0        │      0        │ 0         │ 0        │ 0         │ 0         │  0        │ 0         │ 0        │ 0         │ 0        │ 0        │ 0        │ 0         │ 0.272373 │ 0        │ 0        │ 0         │   0         │ 0        │     0        │ 0        │      0        │ 0         │   0        │       0         │ 0        │   0       │   0        │ 0         │  0         │ 0        │     0        │     0         │ 0         │   0        │  0.382115  │  0        │ 0        │  0        │ 0         │       0       │   0        │ 0        │       0        │     0         │ 0        │ 0        │ 0         │ 0         │  0         │ 0         │            9 │
├──────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼───────────┼───────────┼──────────┼───────────┼──────────┼───────────┼───────────┼──────────┼──────────┼───────────┼─────────┼───────────┼─────────────┼────────────┼─────────────┼───────────────┼──────────┼────────────┼──────────┼─────────────┼───────────┼───────────┼──────────┼───────────────┼───────────────┼───────────┼──────────┼───────────┼───────────┼─────────────┼────────────┼────────────┼───────────┼────────────┼──────────┼───────────┼───────────┼──────────┼─────────────┼─────────────┼──────────┼──────────┼────────────┼───────────┼──────────┼───────────┼───────────┼─────────────┼───────────────┼─────────────────┼──────────────┼──────────────┼───────────┼───────────┼──────────┼──────┼───────────┼──────────┼──────────┼──────────┼────────────┼─────────────┼────────────────┼───────────────┼────────────┼────────────┼──────────────┼──────────────┼──────────┼───────────┼─────────────┼──────────────┼──────────────┼───────────┼─────────┼────────────┼───────────┼────────────────┼──────────────┼──────────┼──────────┼─────────────┼────────────┼───────────────┼──────────┼─────────────┼────────────┼─────────────────┼─────────────┼───────────────┼───────────┼────────────┼───────────────┼──────────┼──────────┼───────────┼────────────┼──────────┼───────────┼──────────────┼──────────┼──────────┼─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼───────────────┼─────────────────┼──────────────┼─────────────┼─────────────┼──────────────┼───────────┼────────────┼──────────────┼───────────────────┼─────────────┼────────────────┼────────────┼───────────┼───────────────┼───────────┼──────────┼───────────┼───────────┼───────────┼───────────┼──────────┼───────────┼──────────┼──────────┼──────────┼───────────┼──────────┼──────────┼──────────┼───────────┼─────────────┼──────────┼──────────────┼──────────┼───────────────┼───────────┼────────────┼─────────────────┼──────────┼───────────┼────────────┼───────────┼────────────┼──────────┼──────────────┼───────────────┼───────────┼────────────┼────────────┼───────────┼──────────┼───────────┼───────────┼───────────────┼────────────┼──────────┼────────────────┼───────────────┼──────────┼──────────┼───────────┼───────────┼────────────┼───────────┼──────────────┤
│    9 │ halhal meringankan mukti ali terdakwa dihukum bersikap sopan persidangan menikmati hasil tindak pidana korupsi .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            │  0        │ 0         │ 0        │ 0         │ 0.224361 │ 0         │ 0         │ 0        │ 0        │ 0         │ 0       │ 0         │   0         │   0        │    0        │      0        │ 0        │   0.322321 │ 0        │    0        │ 0         │ 0         │ 0        │      0        │     0         │  0        │  0       │  0        │  0.322321 │    0        │   0        │   0        │  0        │   0        │ 0        │ 0         │ 0         │ 0        │   0         │    0        │ 0.278973 │ 0.322321 │  0         │ 0         │ 0        │ 0         │ 0         │   0         │      0        │        0        │     0        │     0        │ 0         │  0        │ 0        │    0 │ 0         │ 0        │ 0        │ 0        │   0        │    0        │       0        │      0        │   0        │   0        │    0         │     0        │ 0        │  0        │   0         │     0        │     0        │ 0.161521  │ 0       │   0        │ 0         │      0         │    0         │ 0        │ 0        │    0        │   0        │      0        │ 0        │    0        │   0        │        0        │    0.322321 │      0        │ 0         │   0        │      0.322321 │ 0        │ 0        │ 0         │  0         │ 0.204869 │ 0         │    0         │ 0        │ 0        │    0        │ 0        │ 0        │ 0        │ 0        │ 0        │     0         │        0        │     0        │    0        │     0       │     0        │  0        │   0        │      0       │          0        │    0        │       0        │   0        │  0        │      0.278973 │ 0         │ 0.174114 │ 0         │ 0         │  0        │ 0         │ 0        │ 0         │ 0        │ 0        │ 0        │ 0         │ 0        │ 0        │ 0        │ 0         │   0         │ 0        │     0        │ 0        │      0        │ 0         │   0        │       0         │ 0.322321 │   0       │   0        │ 0         │  0         │ 0        │     0        │     0         │ 0         │   0        │  0.174114  │  0        │ 0.204869 │  0        │ 0         │       0       │   0        │ 0        │       0        │     0         │ 0        │ 0        │ 0         │ 0         │  0         │ 0         │           14 │
├──────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼───────────┼───────────┼──────────┼───────────┼──────────┼───────────┼───────────┼──────────┼──────────┼───────────┼─────────┼───────────┼─────────────┼────────────┼─────────────┼───────────────┼──────────┼────────────┼──────────┼─────────────┼───────────┼───────────┼──────────┼───────────────┼───────────────┼───────────┼──────────┼───────────┼───────────┼─────────────┼────────────┼────────────┼───────────┼────────────┼──────────┼───────────┼───────────┼──────────┼─────────────┼─────────────┼──────────┼──────────┼────────────┼───────────┼──────────┼───────────┼───────────┼─────────────┼───────────────┼─────────────────┼──────────────┼──────────────┼───────────┼───────────┼──────────┼──────┼───────────┼──────────┼──────────┼──────────┼────────────┼─────────────┼────────────────┼───────────────┼────────────┼────────────┼──────────────┼──────────────┼──────────┼───────────┼─────────────┼──────────────┼──────────────┼───────────┼─────────┼────────────┼───────────┼────────────────┼──────────────┼──────────┼──────────┼─────────────┼────────────┼───────────────┼──────────┼─────────────┼────────────┼─────────────────┼─────────────┼───────────────┼───────────┼────────────┼───────────────┼──────────┼──────────┼───────────┼────────────┼──────────┼───────────┼──────────────┼──────────┼──────────┼─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼───────────────┼─────────────────┼──────────────┼─────────────┼─────────────┼──────────────┼───────────┼────────────┼──────────────┼───────────────────┼─────────────┼────────────────┼────────────┼───────────┼───────────────┼───────────┼──────────┼───────────┼───────────┼───────────┼───────────┼──────────┼───────────┼──────────┼──────────┼──────────┼───────────┼──────────┼──────────┼──────────┼───────────┼─────────────┼──────────┼──────────────┼──────────┼───────────────┼───────────┼────────────┼─────────────────┼──────────┼───────────┼────────────┼───────────┼────────────┼──────────┼──────────────┼───────────────┼───────────┼────────────┼────────────┼───────────┼──────────┼───────────┼───────────┼───────────────┼────────────┼──────────┼────────────────┼───────────────┼──────────┼──────────┼───────────┼───────────┼────────────┼───────────┼──────────────┤
│   10 │ baca irwan hermawan dituntut penjara terkait korupsi bts g baca galumbang menak dituntut penjara bts g sidang tuntutan digelar bersamaan tuntutan terdakwa komisaris pt solitech media sinergy irwan hermawan eks direktur utama pt mora telematika indonesia galumbang menak simanjuntak .                                                                                                                                                                                                                                                                                                                                                                                                                                 │  0        │ 0         │ 0        │ 0         │ 0        │ 0         │ 0         │ 0        │ 0.303837 │ 0         │ 0       │ 0         │   0         │   0        │    0.151919 │      0        │ 0        │   0        │ 0.211495 │    0        │ 0         │ 0         │ 0        │      0        │     0         │  0        │  0       │  0.151919 │  0        │    0        │   0        │   0.131488 │  0        │   0.262975 │ 0        │ 0         │ 0         │ 0.151919 │   0         │    0.262975 │ 0        │ 0        │  0.233983  │ 0         │ 0        │ 0         │ 0         │   0.131488  │      0        │        0        │     0        │     0        │ 0.233983  │  0        │ 0        │    0 │ 0         │ 0        │ 0        │ 0        │   0        │    0        │       0        │      0        │   0        │   0        │    0         │     0        │ 0        │  0        │   0.131488  │     0        │     0        │ 0.0761293 │ 0       │   0        │ 0         │      0         │    0         │ 0        │ 0.151919 │    0        │   0        │      0        │ 0.262975 │    0        │   0        │        0        │    0        │      0        │ 0         │   0        │      0        │ 0        │ 0.151919 │ 0         │  0         │ 0        │ 0         │    0         │ 0        │ 0        │    0        │ 0        │ 0        │ 0        │ 0        │ 0        │     0         │        0        │     0        │    0        │     0       │     0        │  0.262975 │   0        │      0       │          0        │    0        │       0        │   0        │  0        │      0        │ 0         │ 0        │ 0         │ 0         │  0        │ 0         │ 0.233983 │ 0         │ 0        │ 0        │ 0        │ 0         │ 0        │ 0        │ 0        │ 0         │   0         │ 0        │     0        │ 0.151919 │      0.151919 │ 0.131488  │   0.151919 │       0         │ 0        │   0       │   0        │ 0         │  0         │ 0        │     0.151919 │     0         │ 0         │   0        │  0.0820643 │  0.151919 │ 0        │  0        │ 0         │       0       │   0.303837 │ 0        │       0        │     0         │ 0.131488 │ 0        │ 0         │ 0         │  0         │ 0         │           27 │
├──────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼───────────┼───────────┼──────────┼───────────┼──────────┼───────────┼───────────┼──────────┼──────────┼───────────┼─────────┼───────────┼─────────────┼────────────┼─────────────┼───────────────┼──────────┼────────────┼──────────┼─────────────┼───────────┼───────────┼──────────┼───────────────┼───────────────┼───────────┼──────────┼───────────┼───────────┼─────────────┼────────────┼────────────┼───────────┼────────────┼──────────┼───────────┼───────────┼──────────┼─────────────┼─────────────┼──────────┼──────────┼────────────┼───────────┼──────────┼───────────┼───────────┼─────────────┼───────────────┼─────────────────┼──────────────┼──────────────┼───────────┼───────────┼──────────┼──────┼───────────┼──────────┼──────────┼──────────┼────────────┼─────────────┼────────────────┼───────────────┼────────────┼────────────┼──────────────┼──────────────┼──────────┼───────────┼─────────────┼──────────────┼──────────────┼───────────┼─────────┼────────────┼───────────┼────────────────┼──────────────┼──────────┼──────────┼─────────────┼────────────┼───────────────┼──────────┼─────────────┼────────────┼─────────────────┼─────────────┼───────────────┼───────────┼────────────┼───────────────┼──────────┼──────────┼───────────┼────────────┼──────────┼───────────┼──────────────┼──────────┼──────────┼─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼───────────────┼─────────────────┼──────────────┼─────────────┼─────────────┼──────────────┼───────────┼────────────┼──────────────┼───────────────────┼─────────────┼────────────────┼────────────┼───────────┼───────────────┼───────────┼──────────┼───────────┼───────────┼───────────┼───────────┼──────────┼───────────┼──────────┼──────────┼──────────┼───────────┼──────────┼──────────┼──────────┼───────────┼─────────────┼──────────┼──────────────┼──────────┼───────────────┼───────────┼────────────┼─────────────────┼──────────┼───────────┼────────────┼───────────┼────────────┼──────────┼──────────────┼───────────────┼───────────┼────────────┼────────────┼───────────┼──────────┼───────────┼───────────┼───────────────┼────────────┼──────────┼────────────────┼───────────────┼──────────┼──────────┼───────────┼───────────┼────────────┼───────────┼──────────────┤
│   11 │ irwan hermawan dituntut pidana penjara galumbang menak dituntut .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           │  0        │ 0         │ 0        │ 0         │ 0        │ 0         │ 0         │ 0        │ 0        │ 0         │ 0       │ 0         │   0         │   0        │    0        │      0        │ 0        │   0        │ 0        │    0        │ 0         │ 0         │ 0        │      0        │     0         │  0        │  0       │  0        │  0        │    0        │   0        │   0        │  0        │   0.667674 │ 0        │ 0         │ 0         │ 0        │   0         │    0.333837 │ 0        │ 0        │  0.297033  │ 0         │ 0        │ 0         │ 0         │   0         │      0        │        0        │     0        │     0        │ 0.297033  │  0        │ 0        │    0 │ 0         │ 0        │ 0        │ 0        │   0        │    0        │       0        │      0        │   0        │   0        │    0         │     0        │ 0        │  0        │   0         │     0        │     0        │ 0         │ 0       │   0        │ 0         │      0         │    0         │ 0        │ 0        │    0        │   0        │      0        │ 0.333837 │    0        │   0        │        0        │    0        │      0        │ 0         │   0        │      0        │ 0        │ 0        │ 0         │  0         │ 0        │ 0         │    0         │ 0        │ 0        │    0        │ 0        │ 0        │ 0        │ 0        │ 0        │     0         │        0        │     0        │    0        │     0       │     0        │  0.333837 │   0        │      0       │          0        │    0        │       0        │   0        │  0        │      0        │ 0         │ 0.208355 │ 0         │ 0         │  0        │ 0         │ 0        │ 0         │ 0        │ 0        │ 0        │ 0         │ 0        │ 0        │ 0        │ 0         │   0         │ 0        │     0        │ 0        │      0        │ 0         │   0        │       0         │ 0        │   0       │   0        │ 0         │  0         │ 0        │     0        │     0         │ 0         │   0        │  0         │  0        │ 0        │  0        │ 0         │       0       │   0        │ 0        │       0        │     0         │ 0        │ 0        │ 0         │ 0         │  0         │ 0         │            7 │
├──────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼───────────┼───────────┼──────────┼───────────┼──────────┼───────────┼───────────┼──────────┼──────────┼───────────┼─────────┼───────────┼─────────────┼────────────┼─────────────┼───────────────┼──────────┼────────────┼──────────┼─────────────┼───────────┼───────────┼──────────┼───────────────┼───────────────┼───────────┼──────────┼───────────┼───────────┼─────────────┼────────────┼────────────┼───────────┼────────────┼──────────┼───────────┼───────────┼──────────┼─────────────┼─────────────┼──────────┼──────────┼────────────┼───────────┼──────────┼───────────┼───────────┼─────────────┼───────────────┼─────────────────┼──────────────┼──────────────┼───────────┼───────────┼──────────┼──────┼───────────┼──────────┼──────────┼──────────┼────────────┼─────────────┼────────────────┼───────────────┼────────────┼────────────┼──────────────┼──────────────┼──────────┼───────────┼─────────────┼──────────────┼──────────────┼───────────┼─────────┼────────────┼───────────┼────────────────┼──────────────┼──────────┼──────────┼─────────────┼────────────┼───────────────┼──────────┼─────────────┼────────────┼─────────────────┼─────────────┼───────────────┼───────────┼────────────┼───────────────┼──────────┼──────────┼───────────┼────────────┼──────────┼───────────┼──────────────┼──────────┼──────────┼─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼───────────────┼─────────────────┼──────────────┼─────────────┼─────────────┼──────────────┼───────────┼────────────┼──────────────┼───────────────────┼─────────────┼────────────────┼────────────┼───────────┼───────────────┼───────────┼──────────┼───────────┼───────────┼───────────┼───────────┼──────────┼───────────┼──────────┼──────────┼──────────┼───────────┼──────────┼──────────┼──────────┼───────────┼─────────────┼──────────┼──────────────┼──────────┼───────────────┼───────────┼────────────┼─────────────────┼──────────┼───────────┼────────────┼───────────┼────────────┼──────────┼──────────────┼───────────────┼───────────┼────────────┼────────────┼───────────┼──────────┼───────────┼───────────┼───────────────┼────────────┼──────────┼────────────────┼───────────────┼──────────┼──────────┼───────────┼───────────┼────────────┼───────────┼──────────────┤
│   12 │ terdakwa diduga tindak pidana korupsi penyediaan infrastruktur base transceiver station bts g infrastruktur pendukung paket bakti kemenkominfo .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            │  0        │ 0         │ 0        │ 0         │ 0        │ 0         │ 0         │ 0        │ 0        │ 0.232866  │ 0.26905 │ 0         │   0         │   0        │    0        │      0        │ 0        │   0        │ 0.18728  │    0        │ 0         │ 0         │ 0        │      0        │     0         │  0        │  0.26905 │  0        │  0        │    0        │   0        │   0        │  0        │   0        │ 0        │ 0         │ 0         │ 0        │   0         │    0        │ 0        │ 0        │  0         │ 0         │ 0        │ 0         │ 0         │   0         │      0        │        0.538099 │     0        │     0        │ 0         │  0        │ 0        │    0 │ 0         │ 0        │ 0        │ 0        │   0        │    0        │       0.207193 │      0        │   0        │   0        │    0         │     0        │ 0        │  0        │   0         │     0        │     0        │ 0.134826  │ 0       │   0        │ 0         │      0         │    0         │ 0        │ 0        │    0        │   0        │      0        │ 0        │    0        │   0        │        0        │    0        │      0        │ 0         │   0        │      0        │ 0        │ 0        │ 0         │  0         │ 0        │ 0         │    0         │ 0        │ 0        │    0        │ 0        │ 0        │ 0        │ 0.232866 │ 0        │     0         │        0        │     0        │    0        │     0.26905 │     0        │  0        │   0        │      0.26905 │          0        │    0        │       0        │   0        │  0        │      0        │ 0         │ 0.145337 │ 0         │ 0         │  0        │ 0         │ 0        │ 0         │ 0        │ 0        │ 0        │ 0         │ 0        │ 0        │ 0        │ 0         │   0         │ 0        │     0        │ 0        │      0        │ 0         │   0        │       0         │ 0        │   0.26905 │   0        │ 0         │  0         │ 0        │     0        │     0         │ 0         │   0        │  0.145337  │  0        │ 0.17101  │  0        │ 0         │       0.26905 │   0        │ 0        │       0        │     0         │ 0        │ 0        │ 0         │ 0         │  0         │ 0         │           15 │
├──────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼───────────┼───────────┼──────────┼───────────┼──────────┼───────────┼───────────┼──────────┼──────────┼───────────┼─────────┼───────────┼─────────────┼────────────┼─────────────┼───────────────┼──────────┼────────────┼──────────┼─────────────┼───────────┼───────────┼──────────┼───────────────┼───────────────┼───────────┼──────────┼───────────┼───────────┼─────────────┼────────────┼────────────┼───────────┼────────────┼──────────┼───────────┼───────────┼──────────┼─────────────┼─────────────┼──────────┼──────────┼────────────┼───────────┼──────────┼───────────┼───────────┼─────────────┼───────────────┼─────────────────┼──────────────┼──────────────┼───────────┼───────────┼──────────┼──────┼───────────┼──────────┼──────────┼──────────┼────────────┼─────────────┼────────────────┼───────────────┼────────────┼────────────┼──────────────┼──────────────┼──────────┼───────────┼─────────────┼──────────────┼──────────────┼───────────┼─────────┼────────────┼───────────┼────────────────┼──────────────┼──────────┼──────────┼─────────────┼────────────┼───────────────┼──────────┼─────────────┼────────────┼─────────────────┼─────────────┼───────────────┼───────────┼────────────┼───────────────┼──────────┼──────────┼───────────┼────────────┼──────────┼───────────┼──────────────┼──────────┼──────────┼─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼───────────────┼─────────────────┼──────────────┼─────────────┼─────────────┼──────────────┼───────────┼────────────┼──────────────┼───────────────────┼─────────────┼────────────────┼────────────┼───────────┼───────────────┼───────────┼──────────┼───────────┼───────────┼───────────┼───────────┼──────────┼───────────┼──────────┼──────────┼──────────┼───────────┼──────────┼──────────┼──────────┼───────────┼─────────────┼──────────┼──────────────┼──────────┼───────────────┼───────────┼────────────┼─────────────────┼──────────┼───────────┼────────────┼───────────┼────────────┼──────────┼──────────────┼───────────────┼───────────┼────────────┼────────────┼───────────┼──────────┼───────────┼───────────┼───────────────┼────────────┼──────────┼────────────────┼───────────────┼──────────┼──────────┼───────────┼───────────┼────────────┼───────────┼──────────────┤
│   13 │ surat dakwaan keuntungan proyek pembangunan mantan menteri kominfo johnny g. plate menerima uang rp ... mantan direktur utama bakti kominfo anang achmad latif menerima uang rp miliar tenaga ahli human development universitas indonesia yohan suryanto menerima rp ... irwan hermawan komisaris pt solitechmedia sinergy menerima rp miliar windi purnama direktur pt multimedia berdikari sejahtera menerima rp juta muhammad yusrizki direktur pt basis utama prima menerima rp miliar juta dolar as konsorsium fiberhome pt telkominfra pt multi trans data pt mtd paket menerima rp .... konsorsium lintasarta huawei sei paket menerima rp .... konsorsium ibs zte paket rp ..... pewarta rivan linggaeditor d.dj . │  0        │ 0.0656823 │ 0        │ 0.0656823 │ 0        │ 0.0656823 │ 0.0656823 │ 0        │ 0        │ 0.0568489 │ 0       │ 0.0656823 │   0.0656823 │   0        │    0        │      0        │ 0        │   0        │ 0        │    0        │ 0.0656823 │ 0.0656823 │ 0        │      0        │     0.0656823 │  0        │  0       │  0        │  0        │    0        │   0        │   0.170547 │  0        │   0        │ 0        │ 0.0656823 │ 0.0656823 │ 0        │   0.0656823 │    0        │ 0        │ 0        │  0.0505815 │ 0.0568489 │ 0        │ 0.0656823 │ 0.0656823 │   0.0568489 │      0        │        0        │     0        │     0        │ 0.0505815 │  0        │ 0        │    0 │ 0.0656823 │ 0        │ 0        │ 0.113698 │   0        │    0        │       0        │      0        │   0        │   0        │    0.0656823 │     0        │ 0        │  0.131365 │   0.0568489 │     0        │     0.197047 │ 0         │ 0       │   0        │ 0.0656823 │      0.0656823 │    0.0656823 │ 0.131365 │ 0        │    0        │   0        │      0        │ 0        │    0        │   0.525458 │        0        │    0        │      0        │ 0.0656823 │   0        │      0        │ 0.197047 │ 0        │ 0.0656823 │  0.0656823 │ 0        │ 0.0656823 │    0.0656823 │ 0        │ 0        │    0        │ 0        │ 0        │ 0        │ 0.170547 │ 0        │     0.0656823 │        0        │     0        │    0        │     0       │     0        │  0        │   0        │      0       │          0        │    0        │       0        │   0        │  0        │      0        │ 0.0656823 │ 0        │ 0.0656823 │ 0.0656823 │  0        │ 0.0656823 │ 0.303489 │ 0.0656823 │ 0        │ 0        │ 0        │ 0.0656823 │ 0.455233 │ 0        │ 0        │ 0.0656823 │   0.0656823 │ 0        │     0        │ 0        │      0        │ 0.0568489 │   0        │       0.0656823 │ 0        │   0       │   0        │ 0.0656823 │  0.0656823 │ 0        │     0        │     0.0656823 │ 0.0656823 │   0        │  0         │  0        │ 0        │  0        │ 0.0656823 │       0       │   0        │ 0.131365 │       0        │     0.0656823 │ 0.113698 │ 0        │ 0.0656823 │ 0.0656823 │  0.0656823 │ 0.0656823 │           63 │
├──────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼───────────┼───────────┼──────────┼───────────┼──────────┼───────────┼───────────┼──────────┼──────────┼───────────┼─────────┼───────────┼─────────────┼────────────┼─────────────┼───────────────┼──────────┼────────────┼──────────┼─────────────┼───────────┼───────────┼──────────┼───────────────┼───────────────┼───────────┼──────────┼───────────┼───────────┼─────────────┼────────────┼────────────┼───────────┼────────────┼──────────┼───────────┼───────────┼──────────┼─────────────┼─────────────┼──────────┼──────────┼────────────┼───────────┼──────────┼───────────┼───────────┼─────────────┼───────────────┼─────────────────┼──────────────┼──────────────┼───────────┼───────────┼──────────┼──────┼───────────┼──────────┼──────────┼──────────┼────────────┼─────────────┼────────────────┼───────────────┼────────────┼────────────┼──────────────┼──────────────┼──────────┼───────────┼─────────────┼──────────────┼──────────────┼───────────┼─────────┼────────────┼───────────┼────────────────┼──────────────┼──────────┼──────────┼─────────────┼────────────┼───────────────┼──────────┼─────────────┼────────────┼─────────────────┼─────────────┼───────────────┼───────────┼────────────┼───────────────┼──────────┼──────────┼───────────┼────────────┼──────────┼───────────┼──────────────┼──────────┼──────────┼─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼───────────────┼─────────────────┼──────────────┼─────────────┼─────────────┼──────────────┼───────────┼────────────┼──────────────┼───────────────────┼─────────────┼────────────────┼────────────┼───────────┼───────────────┼───────────┼──────────┼───────────┼───────────┼───────────┼───────────┼──────────┼───────────┼──────────┼──────────┼──────────┼───────────┼──────────┼──────────┼──────────┼───────────┼─────────────┼──────────┼──────────────┼──────────┼───────────────┼───────────┼────────────┼─────────────────┼──────────┼───────────┼────────────┼───────────┼────────────┼──────────┼──────────────┼───────────────┼───────────┼────────────┼────────────┼───────────┼──────────┼───────────┼───────────┼───────────────┼────────────┼──────────┼────────────────┼───────────────┼──────────┼──────────┼───────────┼───────────┼────────────┼───────────┼──────────────┤
│   14 │ kliwantoro copyright                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        │  0        │ 0         │ 0        │ 0         │ 0        │ 0         │ 0         │ 0        │ 0        │ 0         │ 0       │ 0         │   0         │   0        │    0        │      0        │ 0        │   0        │ 0        │    0.707107 │ 0         │ 0         │ 0        │      0        │     0         │  0        │  0       │  0        │  0        │    0        │   0        │   0        │  0        │   0        │ 0        │ 0         │ 0         │ 0        │   0         │    0        │ 0        │ 0        │  0         │ 0         │ 0        │ 0         │ 0         │   0         │      0        │        0        │     0        │     0        │ 0         │  0        │ 0        │    0 │ 0         │ 0        │ 0        │ 0        │   0        │    0        │       0        │      0        │   0        │   0        │    0         │     0.707107 │ 0        │  0        │   0         │     0        │     0        │ 0         │ 0       │   0        │ 0         │      0         │    0         │ 0        │ 0        │    0        │   0        │      0        │ 0        │    0        │   0        │        0        │    0        │      0        │ 0         │   0        │      0        │ 0        │ 0        │ 0         │  0         │ 0        │ 0         │    0         │ 0        │ 0        │    0        │ 0        │ 0        │ 0        │ 0        │ 0        │     0         │        0        │     0        │    0        │     0       │     0        │  0        │   0        │      0       │          0        │    0        │       0        │   0        │  0        │      0        │ 0         │ 0        │ 0         │ 0         │  0        │ 0         │ 0        │ 0         │ 0        │ 0        │ 0        │ 0         │ 0        │ 0        │ 0        │ 0         │   0         │ 0        │     0        │ 0        │      0        │ 0         │   0        │       0         │ 0        │   0       │   0        │ 0         │  0         │ 0        │     0        │     0         │ 0         │   0        │  0         │  0        │ 0        │  0        │ 0         │       0       │   0        │ 0        │       0        │     0         │ 0        │ 0        │ 0         │ 0         │  0         │ 0         │            2 │
╘══════╧═════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╧═══════════╧═══════════╧══════════╧═══════════╧══════════╧═══════════╧═══════════╧══════════╧══════════╧═══════════╧═════════╧═══════════╧═════════════╧════════════╧═════════════╧═══════════════╧══════════╧════════════╧══════════╧═════════════╧═══════════╧═══════════╧══════════╧═══════════════╧═══════════════╧═══════════╧══════════╧═══════════╧═══════════╧═════════════╧════════════╧════════════╧═══════════╧════════════╧══════════╧═══════════╧═══════════╧══════════╧═════════════╧═════════════╧══════════╧══════════╧════════════╧═══════════╧══════════╧═══════════╧═══════════╧═════════════╧═══════════════╧═════════════════╧══════════════╧══════════════╧═══════════╧═══════════╧══════════╧══════╧═══════════╧══════════╧══════════╧══════════╧════════════╧═════════════╧════════════════╧═══════════════╧════════════╧════════════╧══════════════╧══════════════╧══════════╧═══════════╧═════════════╧══════════════╧══════════════╧═══════════╧═════════╧════════════╧═══════════╧════════════════╧══════════════╧══════════╧══════════╧═════════════╧════════════╧═══════════════╧══════════╧═════════════╧════════════╧═════════════════╧═════════════╧═══════════════╧═══════════╧════════════╧═══════════════╧══════════╧══════════╧═══════════╧════════════╧══════════╧═══════════╧══════════════╧══════════╧══════════╧═════════════╧══════════╧══════════╧══════════╧══════════╧══════════╧═══════════════╧═════════════════╧══════════════╧═════════════╧═════════════╧══════════════╧═══════════╧════════════╧══════════════╧═══════════════════╧═════════════╧════════════════╧════════════╧═══════════╧═══════════════╧═══════════╧══════════╧═══════════╧═══════════╧═══════════╧═══════════╧══════════╧═══════════╧══════════╧══════════╧══════════╧═══════════╧══════════╧══════════╧══════════╧═══════════╧═════════════╧══════════╧══════════════╧══════════╧═══════════════╧═══════════╧════════════╧═════════════════╧══════════╧═══════════╧════════════╧═══════════╧════════════╧══════════╧══════════════╧═══════════════╧═══════════╧════════════╧════════════╧═══════════╧══════════╧═══════════╧═══════════╧═══════════════╧════════════╧══════════╧════════════════╧═══════════════╧══════════╧══════════╧═══════════╧═══════════╧════════════╧═══════════╧══════════════╛
</pre></div>
</div>
</div>
</div>
</section>
<section id="cosine-similarity">
<h1><strong>Cosine Similarity</strong><a class="headerlink" href="#cosine-similarity" title="Permalink to this heading">#</a></h1>
<p>Cosine similarity (similaritas kosinus) adalah metode yang digunakan untuk mengukur sejauh mana dua vektor arah berada dalam hubungan linear satu sama lain. Dalam konteks pemrosesan bahasa alami dan pengelompokan data, metode ini sering digunakan untuk membandingkan dokumen atau teks.</p>
<p>Proses perhitungan cosine similarity melibatkan mengukur sudut antara dua vektor dokumen. Hasilnya adalah nilai antara -1 dan 1, di mana nilai 1 menunjukkan bahwa dua vektor memiliki arah yang sama, nilai -1 menunjukkan arah yang berlawanan, dan nilai 0 menunjukkan bahwa vektor tersebut bersifat ortogonal atau tidak memiliki kesamaan arah.</p>
<p>Rumus :</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>

<span class="c1"># Indeks kalimat yang akan dibandingkan</span>
<span class="n">sentence1_index</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Ganti dengan indeks kalimat pertama yang ingin Anda bandingkan</span>
<span class="n">sentence2_index</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># Ganti dengan indeks kalimat kedua yang ingin Anda bandingkan</span>

<span class="c1"># Ambil vektor TF-IDF untuk kedua kalimat</span>
<span class="n">tfidf_vector1</span> <span class="o">=</span> <span class="n">tfidf_matrix</span><span class="p">[</span><span class="n">sentence1_index</span><span class="p">]</span>
<span class="n">tfidf_vector2</span> <span class="o">=</span> <span class="n">tfidf_matrix</span><span class="p">[</span><span class="n">sentence2_index</span><span class="p">]</span>

<span class="c1"># Hitung cosine similarity antara kedua vektor</span>
<span class="n">similarity</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">tfidf_vector1</span><span class="p">,</span> <span class="n">tfidf_vector2</span><span class="p">)</span>

<span class="c1"># Cetak hasil cosine similarity</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cosine Similarity antara Kalimat </span><span class="si">{</span><span class="n">sentence1_index</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2"> dan Kalimat </span><span class="si">{</span><span class="n">sentence2_index</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">similarity</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cosine Similarity antara Kalimat 1 dan Kalimat 2: 0.1130
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Matriks TF-IDF telah dihitung sebelumnya (tfidf_matrix)</span>

<span class="c1"># Hitung cosine similarity antara semua pasangan kalimat</span>
<span class="n">similarity_matrix</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">tfidf_matrix</span><span class="p">,</span> <span class="n">tfidf_matrix</span><span class="p">)</span>

<span class="c1"># Cetak hasil similarity_matrix</span>
<span class="n">num_sentences</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span>  <span class="c1"># Jumlah kalimat</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_sentences</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_sentences</span><span class="p">):</span>
        <span class="n">similarity</span> <span class="o">=</span> <span class="n">similarity_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cosine Similarity antara Kalimat </span><span class="si">{</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2"> dan Kalimat </span><span class="si">{</span><span class="n">j</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">similarity</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cosine Similarity antara Kalimat 1 dan Kalimat 2: 0.1130
Cosine Similarity antara Kalimat 1 dan Kalimat 3: 0.3002
Cosine Similarity antara Kalimat 1 dan Kalimat 4: 0.0455
Cosine Similarity antara Kalimat 1 dan Kalimat 5: 0.0000
Cosine Similarity antara Kalimat 1 dan Kalimat 6: 0.0000
Cosine Similarity antara Kalimat 1 dan Kalimat 7: 0.0131
Cosine Similarity antara Kalimat 1 dan Kalimat 8: 0.0688
Cosine Similarity antara Kalimat 1 dan Kalimat 9: 0.0833
Cosine Similarity antara Kalimat 1 dan Kalimat 10: 0.0660
Cosine Similarity antara Kalimat 1 dan Kalimat 11: 0.0203
Cosine Similarity antara Kalimat 1 dan Kalimat 12: 0.0787
Cosine Similarity antara Kalimat 1 dan Kalimat 13: 0.1321
Cosine Similarity antara Kalimat 1 dan Kalimat 14: 0.0000
Cosine Similarity antara Kalimat 2 dan Kalimat 3: 0.2342
Cosine Similarity antara Kalimat 2 dan Kalimat 4: 0.0926
Cosine Similarity antara Kalimat 2 dan Kalimat 5: 0.0000
Cosine Similarity antara Kalimat 2 dan Kalimat 6: 0.0000
Cosine Similarity antara Kalimat 2 dan Kalimat 7: 0.0687
Cosine Similarity antara Kalimat 2 dan Kalimat 8: 0.1673
Cosine Similarity antara Kalimat 2 dan Kalimat 9: 0.2560
Cosine Similarity antara Kalimat 2 dan Kalimat 10: 0.0362
Cosine Similarity antara Kalimat 2 dan Kalimat 11: 0.0476
Cosine Similarity antara Kalimat 2 dan Kalimat 12: 0.1204
Cosine Similarity antara Kalimat 2 dan Kalimat 13: 0.0000
Cosine Similarity antara Kalimat 2 dan Kalimat 14: 0.0000
Cosine Similarity antara Kalimat 3 dan Kalimat 4: 0.1141
Cosine Similarity antara Kalimat 3 dan Kalimat 5: 0.0000
Cosine Similarity antara Kalimat 3 dan Kalimat 6: 0.0000
Cosine Similarity antara Kalimat 3 dan Kalimat 7: 0.0496
Cosine Similarity antara Kalimat 3 dan Kalimat 8: 0.1198
Cosine Similarity antara Kalimat 3 dan Kalimat 9: 0.2175
Cosine Similarity antara Kalimat 3 dan Kalimat 10: 0.0729
Cosine Similarity antara Kalimat 3 dan Kalimat 11: 0.0357
Cosine Similarity antara Kalimat 3 dan Kalimat 12: 0.1977
Cosine Similarity antara Kalimat 3 dan Kalimat 13: 0.0000
Cosine Similarity antara Kalimat 3 dan Kalimat 14: 0.0000
Cosine Similarity antara Kalimat 4 dan Kalimat 5: 0.0000
Cosine Similarity antara Kalimat 4 dan Kalimat 6: 0.3787
Cosine Similarity antara Kalimat 4 dan Kalimat 7: 0.0193
Cosine Similarity antara Kalimat 4 dan Kalimat 8: 0.0000
Cosine Similarity antara Kalimat 4 dan Kalimat 9: 0.1160
Cosine Similarity antara Kalimat 4 dan Kalimat 10: 0.0102
Cosine Similarity antara Kalimat 4 dan Kalimat 11: 0.0300
Cosine Similarity antara Kalimat 4 dan Kalimat 12: 0.0679
Cosine Similarity antara Kalimat 4 dan Kalimat 13: 0.0000
Cosine Similarity antara Kalimat 4 dan Kalimat 14: 0.0000
Cosine Similarity antara Kalimat 5 dan Kalimat 6: 0.0000
Cosine Similarity antara Kalimat 5 dan Kalimat 7: 0.0000
Cosine Similarity antara Kalimat 5 dan Kalimat 8: 0.0000
Cosine Similarity antara Kalimat 5 dan Kalimat 9: 0.0000
Cosine Similarity antara Kalimat 5 dan Kalimat 10: 0.0000
Cosine Similarity antara Kalimat 5 dan Kalimat 11: 0.0000
Cosine Similarity antara Kalimat 5 dan Kalimat 12: 0.0000
Cosine Similarity antara Kalimat 5 dan Kalimat 13: 0.0000
Cosine Similarity antara Kalimat 5 dan Kalimat 14: 0.0000
Cosine Similarity antara Kalimat 6 dan Kalimat 7: 0.0000
Cosine Similarity antara Kalimat 6 dan Kalimat 8: 0.0000
Cosine Similarity antara Kalimat 6 dan Kalimat 9: 0.0000
Cosine Similarity antara Kalimat 6 dan Kalimat 10: 0.0000
Cosine Similarity antara Kalimat 6 dan Kalimat 11: 0.0000
Cosine Similarity antara Kalimat 6 dan Kalimat 12: 0.0000
Cosine Similarity antara Kalimat 6 dan Kalimat 13: 0.0000
Cosine Similarity antara Kalimat 6 dan Kalimat 14: 0.0000
Cosine Similarity antara Kalimat 7 dan Kalimat 8: 0.1358
Cosine Similarity antara Kalimat 7 dan Kalimat 9: 0.1200
Cosine Similarity antara Kalimat 7 dan Kalimat 10: 0.0238
Cosine Similarity antara Kalimat 7 dan Kalimat 11: 0.0000
Cosine Similarity antara Kalimat 7 dan Kalimat 12: 0.0421
Cosine Similarity antara Kalimat 7 dan Kalimat 13: 0.0000
Cosine Similarity antara Kalimat 7 dan Kalimat 14: 0.0000
Cosine Similarity antara Kalimat 8 dan Kalimat 9: 0.0665
Cosine Similarity antara Kalimat 8 dan Kalimat 10: 0.0314
Cosine Similarity antara Kalimat 8 dan Kalimat 11: 0.0000
Cosine Similarity antara Kalimat 8 dan Kalimat 12: 0.0555
Cosine Similarity antara Kalimat 8 dan Kalimat 13: 0.1240
Cosine Similarity antara Kalimat 8 dan Kalimat 14: 0.0000
Cosine Similarity antara Kalimat 9 dan Kalimat 10: 0.0266
Cosine Similarity antara Kalimat 9 dan Kalimat 11: 0.0363
Cosine Similarity antara Kalimat 9 dan Kalimat 12: 0.1074
Cosine Similarity antara Kalimat 9 dan Kalimat 13: 0.0000
Cosine Similarity antara Kalimat 9 dan Kalimat 14: 0.0000
Cosine Similarity antara Kalimat 10 dan Kalimat 11: 0.5780
Cosine Similarity antara Kalimat 10 dan Kalimat 12: 0.0618
Cosine Similarity antara Kalimat 10 dan Kalimat 13: 0.1545
Cosine Similarity antara Kalimat 10 dan Kalimat 14: 0.0000
Cosine Similarity antara Kalimat 11 dan Kalimat 12: 0.0303
Cosine Similarity antara Kalimat 11 dan Kalimat 13: 0.0300
Cosine Similarity antara Kalimat 11 dan Kalimat 14: 0.0000
Cosine Similarity antara Kalimat 12 dan Kalimat 13: 0.0530
Cosine Similarity antara Kalimat 12 dan Kalimat 14: 0.0000
Cosine Similarity antara Kalimat 13 dan Kalimat 14: 0.0000
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Matriks TF-IDF telah dihitung sebelumnya (tfidf_matrix)</span>
<span class="c1"># Hitung cosine similarity antara semua pasangan kalimat</span>
<span class="n">similarity_matrix</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">tfidf_matrix</span><span class="p">,</span> <span class="n">tfidf_matrix</span><span class="p">)</span>

<span class="c1"># Nama kolom dan indeks untuk DataFrame</span>
<span class="n">sentence_indices</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;Kalimat </span><span class="si">{</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">))]</span>

<span class="c1"># Buat DataFrame dari hasil cosine similarity</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">similarity_matrix</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">sentence_indices</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">sentence_indices</span><span class="p">)</span>

<span class="c1"># Cetak DataFrame</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-be8f1c2c-1bef-429d-b510-355e22ae8c3c" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Kalimat 1</th>
      <th>Kalimat 2</th>
      <th>Kalimat 3</th>
      <th>Kalimat 4</th>
      <th>Kalimat 5</th>
      <th>Kalimat 6</th>
      <th>Kalimat 7</th>
      <th>Kalimat 8</th>
      <th>Kalimat 9</th>
      <th>Kalimat 10</th>
      <th>Kalimat 11</th>
      <th>Kalimat 12</th>
      <th>Kalimat 13</th>
      <th>Kalimat 14</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Kalimat 1</th>
      <td>1.000000</td>
      <td>0.113006</td>
      <td>0.300190</td>
      <td>0.045537</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.013067</td>
      <td>0.068814</td>
      <td>0.083306</td>
      <td>0.066003</td>
      <td>0.020322</td>
      <td>0.078721</td>
      <td>0.132149</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Kalimat 2</th>
      <td>0.113006</td>
      <td>1.000000</td>
      <td>0.234157</td>
      <td>0.092611</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.068717</td>
      <td>0.167347</td>
      <td>0.255964</td>
      <td>0.036225</td>
      <td>0.047647</td>
      <td>0.120397</td>
      <td>0.000000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Kalimat 3</th>
      <td>0.300190</td>
      <td>0.234157</td>
      <td>1.000000</td>
      <td>0.114143</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.049634</td>
      <td>0.119846</td>
      <td>0.217513</td>
      <td>0.072868</td>
      <td>0.035705</td>
      <td>0.197699</td>
      <td>0.000000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Kalimat 4</th>
      <td>0.045537</td>
      <td>0.092611</td>
      <td>0.114143</td>
      <td>1.000000</td>
      <td>0.0</td>
      <td>0.378702</td>
      <td>0.019275</td>
      <td>0.000000</td>
      <td>0.115974</td>
      <td>0.010161</td>
      <td>0.029977</td>
      <td>0.067856</td>
      <td>0.000000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Kalimat 5</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Kalimat 6</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.378702</td>
      <td>0.0</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Kalimat 7</th>
      <td>0.013067</td>
      <td>0.068717</td>
      <td>0.049634</td>
      <td>0.019275</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.135839</td>
      <td>0.120013</td>
      <td>0.023769</td>
      <td>0.000000</td>
      <td>0.042095</td>
      <td>0.000000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Kalimat 8</th>
      <td>0.068814</td>
      <td>0.167347</td>
      <td>0.119846</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.135839</td>
      <td>1.000000</td>
      <td>0.066531</td>
      <td>0.031358</td>
      <td>0.000000</td>
      <td>0.055535</td>
      <td>0.123993</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Kalimat 9</th>
      <td>0.083306</td>
      <td>0.255964</td>
      <td>0.217513</td>
      <td>0.115974</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.120013</td>
      <td>0.066531</td>
      <td>1.000000</td>
      <td>0.026585</td>
      <td>0.036277</td>
      <td>0.107422</td>
      <td>0.000000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Kalimat 10</th>
      <td>0.066003</td>
      <td>0.036225</td>
      <td>0.072868</td>
      <td>0.010161</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.023769</td>
      <td>0.031358</td>
      <td>0.026585</td>
      <td>1.000000</td>
      <td>0.577956</td>
      <td>0.061800</td>
      <td>0.154481</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Kalimat 11</th>
      <td>0.020322</td>
      <td>0.047647</td>
      <td>0.035705</td>
      <td>0.029977</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.036277</td>
      <td>0.577956</td>
      <td>1.000000</td>
      <td>0.030282</td>
      <td>0.030049</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Kalimat 12</th>
      <td>0.078721</td>
      <td>0.120397</td>
      <td>0.197699</td>
      <td>0.067856</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.042095</td>
      <td>0.055535</td>
      <td>0.107422</td>
      <td>0.061800</td>
      <td>0.030282</td>
      <td>1.000000</td>
      <td>0.052953</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Kalimat 13</th>
      <td>0.132149</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.123993</td>
      <td>0.000000</td>
      <td>0.154481</td>
      <td>0.030049</td>
      <td>0.052953</td>
      <td>1.000000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Kalimat 14</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">
      
  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-be8f1c2c-1bef-429d-b510-355e22ae8c3c')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">
      
  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>
    
  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-be8f1c2c-1bef-429d-b510-355e22ae8c3c button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-be8f1c2c-1bef-429d-b510-355e22ae8c3c');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>
  
    </div>
  </div>
  </div></div>
</div>
</section>
<section id="closeness-centrality">
<h1><strong>Closeness Centrality</strong><a class="headerlink" href="#closeness-centrality" title="Permalink to this heading">#</a></h1>
<p>Closeness centrality adalah suatu metrik dalam teori graf yang mengukur seberapa dekat suatu node dengan semua node lainnya dalam sebuah graf. Node dengan closeness centrality yang tinggi dianggap “sentral” atau “dekat” dengan node lainnya. Metrik ini berguna dalam mengidentifikasi node yang memiliki aksesibilitas yang tinggi dalam graf</p>
<p>Rumus:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Diasumsikan similarity_matrix sudah didefinisikan sebelumnya</span>
<span class="c1"># Contoh similarity_matrix</span>

<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">similarity_matrix</span><span class="p">)):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">similarity_matrix</span><span class="p">[</span><span class="mi">0</span><span class="p">])):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">j</span><span class="p">:</span>
            <span class="n">similarity</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">similarity_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">],</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Bulatkan nilai ke 2 angka dibelakang koma</span>
            <span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="n">similarity</span><span class="p">)</span>

<span class="c1"># Visualisasi grafik</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">pos</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">spring_layout</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>  <span class="c1"># Menentukan layout grafik</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">font_weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>  <span class="c1"># Menggambar grafik dengan label node</span>
<span class="n">edge_labels</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">get_edge_attributes</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">)</span>  <span class="c1"># Mendapatkan atribut edge (bobot)</span>
<span class="c1"># Mengubah nilai bobot menjadi string dengan 2 angka di belakang koma</span>
<span class="n">edge_labels</span> <span class="o">=</span> <span class="p">{(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">):</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">weight</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">),</span> <span class="n">weight</span> <span class="ow">in</span> <span class="n">edge_labels</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx_edge_labels</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">edge_labels</span><span class="o">=</span><span class="n">edge_labels</span><span class="p">)</span>  <span class="c1"># Menampilkan label bobot pada edge</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Visualisasi Graph dengan Kesamaan Kosinus (Bulatan 2 Desimal)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/2bec568dd23e52b122e4e89a5d9b5dd0aa6a590fe8a12201ddf91efaae6c9de3.png" src="_images/2bec568dd23e52b122e4e89a5d9b5dd0aa6a590fe8a12201ddf91efaae6c9de3.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Diasumsikan similarity_matrix sudah didefinisikan sebelumnya</span>
<span class="c1"># Contoh similarity_matrix</span>

<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="n">threshold</span> <span class="o">=</span> <span class="mf">0.06</span>  <span class="c1"># Threshold untuk menyambungkan node</span>

<span class="c1"># Tambahkan semua node ke grafik</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_nodes_from</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">similarity_matrix</span><span class="p">)))</span>

<span class="c1"># Tambahkan edge antara node yang nilainya melebihi threshold</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">similarity_matrix</span><span class="p">)):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">similarity_matrix</span><span class="p">[</span><span class="mi">0</span><span class="p">])):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">j</span> <span class="ow">and</span> <span class="n">similarity_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">:</span>
            <span class="n">similarity</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">similarity_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">],</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Bulatkan nilai ke 2 angka dibelakang koma</span>
            <span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="n">similarity</span><span class="p">)</span>

<span class="c1"># Visualisasi grafik</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">pos</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">spring_layout</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>  <span class="c1"># Menentukan layout grafik</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">font_weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>  <span class="c1"># Menggambar grafik dengan label node</span>
<span class="n">edge_labels</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">get_edge_attributes</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">)</span>  <span class="c1"># Mendapatkan atribut edge (bobot)</span>
<span class="c1"># Mengubah nilai bobot menjadi string dengan 2 angka di belakang koma</span>
<span class="n">edge_labels</span> <span class="o">=</span> <span class="p">{(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">):</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">weight</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">),</span> <span class="n">weight</span> <span class="ow">in</span> <span class="n">edge_labels</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx_edge_labels</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">edge_labels</span><span class="o">=</span><span class="n">edge_labels</span><span class="p">)</span>  <span class="c1"># Menampilkan label bobot pada edge</span>

<span class="c1"># Tambahkan label pada node yang tidak terhubung</span>
<span class="n">isolated_nodes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">isolates</span><span class="p">(</span><span class="n">G</span><span class="p">))</span>
<span class="k">if</span> <span class="n">isolated_nodes</span><span class="p">:</span>
    <span class="c1"># isolated_nodes_labels = {node: f&#39;Node {node} (Not connected)&#39; for node in isolated_nodes}</span>
    <span class="n">pos_extra</span> <span class="o">=</span> <span class="p">{</span><span class="n">node</span><span class="p">:</span> <span class="p">(</span><span class="n">pos</span><span class="p">[</span><span class="n">node</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">pos</span><span class="p">[</span><span class="n">node</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">)</span> <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">isolated_nodes</span><span class="p">}</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Visualisasi Graph dengan Kesamaan Kosinus (Threshold: </span><span class="si">{</span><span class="n">threshold</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/33e3e478e202063b75eeb1e3bd480342c51425d2b14859acd20f58b4c1468d5e.png" src="_images/33e3e478e202063b75eeb1e3bd480342c51425d2b14859acd20f58b4c1468d5e.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Diasumsikan similarity_matrix sudah didefinisikan sebelumnya</span>
<span class="c1"># Contoh similarity_matrix</span>

<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="n">threshold</span> <span class="o">=</span> <span class="mf">0.06</span>  <span class="c1"># Threshold untuk menyambungkan node</span>

<span class="c1"># Tambahkan semua node ke grafik</span>
<span class="n">num_nodes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">similarity_matrix</span><span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_nodes_from</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">))</span>

<span class="c1"># Tambahkan edge antara node yang nilainya melebihi threshold</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">j</span> <span class="ow">and</span> <span class="n">similarity_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">:</span>
            <span class="n">similarity</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">similarity_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">],</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Bulatkan nilai ke 2 angka dibelakang koma</span>
            <span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="n">similarity</span><span class="p">)</span>

<span class="c1"># Visualisasi grafik</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">pos</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">spring_layout</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>  <span class="c1"># Menentukan layout grafik</span>

<span class="c1"># Buat mapping untuk label node</span>
<span class="n">node_labels</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;Kalimat </span><span class="si">{</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">)}</span>

<span class="n">nx</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">node_labels</span><span class="p">,</span> <span class="n">font_weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>  <span class="c1"># Menggambar grafik dengan label node</span>
<span class="n">edge_labels</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">get_edge_attributes</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">)</span>  <span class="c1"># Mendapatkan atribut edge (bobot)</span>
<span class="c1"># Mengubah nilai bobot menjadi string dengan 2 angka di belakang koma</span>
<span class="n">edge_labels</span> <span class="o">=</span> <span class="p">{(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">):</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">weight</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">),</span> <span class="n">weight</span> <span class="ow">in</span> <span class="n">edge_labels</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx_edge_labels</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">edge_labels</span><span class="o">=</span><span class="n">edge_labels</span><span class="p">)</span>  <span class="c1"># Menampilkan label bobot pada edge</span>

<span class="c1"># Tambahkan label pada node yang tidak terhubung</span>
<span class="n">isolated_nodes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">isolates</span><span class="p">(</span><span class="n">G</span><span class="p">))</span>
<span class="k">if</span> <span class="n">isolated_nodes</span><span class="p">:</span>
    <span class="n">pos_extra</span> <span class="o">=</span> <span class="p">{</span><span class="n">node</span><span class="p">:</span> <span class="p">(</span><span class="n">pos</span><span class="p">[</span><span class="n">node</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">pos</span><span class="p">[</span><span class="n">node</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">)</span> <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">isolated_nodes</span><span class="p">}</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Visualisasi Graph dengan Kesamaan Kosinus (Threshold: </span><span class="si">{</span><span class="n">threshold</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/1ae5814fe5dc279d36733170eb31a8d6c37de6a7231a36d3aee186c046bfb657.png" src="_images/1ae5814fe5dc279d36733170eb31a8d6c37de6a7231a36d3aee186c046bfb657.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Diasumsikan similarity_matrix sudah didefinisikan sebelumnya</span>
<span class="c1"># Contoh similarity_matrix</span>

<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">DiGraph</span><span class="p">()</span>  <span class="c1"># Menggunakan Directed Graph agar dapat mengakses in_degree dan out_degree</span>
<span class="n">threshold</span> <span class="o">=</span> <span class="mf">0.06</span>  <span class="c1"># Threshold untuk menyambungkan node</span>

<span class="c1"># Tambahkan semua node ke grafik</span>
<span class="n">num_nodes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">similarity_matrix</span><span class="p">)</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_nodes_from</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">))</span>

<span class="c1"># Tambahkan edge antara node yang nilainya melebihi threshold</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">j</span> <span class="ow">and</span> <span class="n">similarity_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">:</span>
            <span class="n">similarity</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">similarity_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">],</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Bulatkan nilai ke 2 angka dibelakang koma</span>
            <span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="n">similarity</span><span class="p">)</span>

<span class="c1"># Hitung indegree dan outdegree untuk setiap node</span>
<span class="n">indegree</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">in_degree</span><span class="p">())</span>
<span class="n">outdegree</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">out_degree</span><span class="p">())</span>

<span class="c1"># Visualisasi grafik</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">pos</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">spring_layout</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>  <span class="c1"># Menentukan layout grafik</span>

<span class="c1"># Buat mapping untuk label node</span>
<span class="n">node_labels</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;Kalimat </span><span class="si">{</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="se">\n</span><span class="s2">In: </span><span class="si">{</span><span class="n">indegree</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">, Out: </span><span class="si">{</span><span class="n">outdegree</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">)}</span>

<span class="n">nx</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">node_labels</span><span class="p">,</span> <span class="n">font_weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>  <span class="c1"># Menggambar grafik dengan label node</span>
<span class="n">edge_labels</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">get_edge_attributes</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">)</span>  <span class="c1"># Mendapatkan atribut edge (bobot)</span>
<span class="c1"># Mengubah nilai bobot menjadi string dengan 2 angka di belakang koma</span>
<span class="n">edge_labels</span> <span class="o">=</span> <span class="p">{(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">):</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">weight</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">),</span> <span class="n">weight</span> <span class="ow">in</span> <span class="n">edge_labels</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx_edge_labels</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">edge_labels</span><span class="o">=</span><span class="n">edge_labels</span><span class="p">)</span>  <span class="c1"># Menampilkan label bobot pada edge</span>

<span class="c1"># Tambahkan label pada node yang tidak terhubung</span>
<span class="n">isolated_nodes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">isolates</span><span class="p">(</span><span class="n">G</span><span class="p">))</span>
<span class="k">if</span> <span class="n">isolated_nodes</span><span class="p">:</span>
    <span class="n">pos_extra</span> <span class="o">=</span> <span class="p">{</span><span class="n">node</span><span class="p">:</span> <span class="p">(</span><span class="n">pos</span><span class="p">[</span><span class="n">node</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">pos</span><span class="p">[</span><span class="n">node</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">)</span> <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">isolated_nodes</span><span class="p">}</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Visualisasi Graph dengan Kesamaan Kosinus (Threshold: </span><span class="si">{</span><span class="n">threshold</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/ffd0aa961e6a661458adda88b695e010d6fa8dd146f3e5196e386d9347841058.png" src="_images/ffd0aa961e6a661458adda88b695e010d6fa8dd146f3e5196e386d9347841058.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Menghitung closeness centrality dari graph</span>
<span class="n">closeness</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">closeness_centrality</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>

<span class="c1"># Menampilkan closeness centrality</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Closeness Centrality:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">node</span><span class="p">,</span> <span class="n">closeness_value</span> <span class="ow">in</span> <span class="n">closeness</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Node </span><span class="si">{</span><span class="n">node</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">closeness_value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Menampilkan kalimat dengan Closeness Centrality tertinggi</span>
<span class="n">sorted_closeness</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">closeness</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=============================&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Top 4 sentences based on Closeness Centrality:&quot;</span><span class="p">)</span>
<span class="n">num_sentences_to_display</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sorted_closeness</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_sentences_to_display</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">sentence</span><span class="p">[</span><span class="n">sorted_closeness</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Node </span><span class="si">{</span><span class="n">sorted_closeness</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> tidak ditemukan dalam kalimat.&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=============================&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Top 3 node based on Closeness Centrality:&quot;</span><span class="p">)</span>
<span class="n">num_nodes_to_display</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sorted_closeness</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_nodes_to_display</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Node </span><span class="si">{</span><span class="n">sorted_closeness</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> dengan Closeness Centrality </span><span class="si">{</span><span class="n">sorted_closeness</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Closeness Centrality:
Node 0: 0.5817307692307693
Node 1: 0.5817307692307693
Node 2: 0.6205128205128204
Node 3: 0.4898785425101215
Node 4: 0.0
Node 5: 0.3209549071618037
Node 6: 0.40468227424749165
Node 7: 0.5170940170940171
Node 8: 0.5817307692307693
Node 9: 0.4898785425101215
Node 10: 0.3209549071618037
Node 11: 0.5817307692307693
Node 12: 0.4230769230769231
Node 13: 0.0
=============================
Top 4 sentences based on Closeness Centrality:
antara
kliwantoro
copyright
Node 8 tidak ditemukan dalam kalimat.
=============================
Top 3 node based on Closeness Centrality:
Node 2 dengan Closeness Centrality 0.6205
Node 0 dengan Closeness Centrality 0.5817
Node 1 dengan Closeness Centrality 0.5817
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Hitung PageRank</span>
<span class="n">pagerank</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">pagerank</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>

<span class="c1"># Menampilkan PageRank</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;PageRank:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">node</span><span class="p">,</span> <span class="n">rank</span> <span class="ow">in</span> <span class="n">pagerank</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Kalimat </span><span class="si">{</span><span class="n">node</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Menampilkan kalimat dengan PageRank tertinggi</span>
<span class="n">sorted_pagerank</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">pagerank</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=============================&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Top 4 kalimat based on PageRank:&quot;</span><span class="p">)</span>
<span class="n">num_sentences_to_display</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sorted_pagerank</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_sentences_to_display</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">sentence</span><span class="p">[</span><span class="n">sorted_closeness</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Node </span><span class="si">{</span><span class="n">sorted_closeness</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> tidak ditemukan dalam kalimat.&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=============================&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Top 3 kalimat based on PageRank:&quot;</span><span class="p">)</span>
<span class="n">num_nodes_to_display</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sorted_pagerank</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_nodes_to_display</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Kalimat </span><span class="si">{</span><span class="n">sorted_pagerank</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2"> dengan PageRank </span><span class="si">{</span><span class="n">sorted_pagerank</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>PageRank:
Kalimat 1: 0.08930174353993188
Kalimat 2: 0.10920680225550966
Kalimat 3: 0.1267218647605153
Kalimat 4: 0.08891341328234441
Kalimat 5: 0.012195121951219514
Kalimat 6: 0.04949240053094441
Kalimat 7: 0.042605281710168585
Kalimat 8: 0.07815193990892233
Kalimat 9: 0.10322187378234166
Kalimat 10: 0.10239107636484979
Kalimat 11: 0.0664705806593151
Kalimat 12: 0.06960067052104862
Kalimat 13: 0.04953210878166959
Kalimat 14: 0.012195121951219514
=============================
Top 4 kalimat based on PageRank:
antara
kliwantoro
copyright
Node 8 tidak ditemukan dalam kalimat.
=============================
Top 3 kalimat based on PageRank:
Kalimat 3 dengan PageRank 0.1267
Kalimat 2 dengan PageRank 0.1092
Kalimat 9 dengan PageRank 0.1032
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>

<span class="c1"># Buat graf</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edges_from</span><span class="p">(</span><span class="n">edge_labels</span><span class="p">)</span>

<span class="c1"># Inisialisasi PageRank</span>
<span class="n">pagerank</span> <span class="o">=</span> <span class="p">{</span><span class="n">node</span><span class="p">:</span> <span class="mi">1</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">nodes</span><span class="p">)</span> <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">G</span><span class="o">.</span><span class="n">nodes</span><span class="p">}</span>

<span class="c1"># Iterasi untuk menghitung PageRank</span>
<span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">10</span>

<span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Iterasi </span><span class="si">{</span><span class="n">iteration</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
    <span class="n">new_pagerank</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">damping_factor</span> <span class="o">=</span> <span class="mf">0.85</span>

    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">G</span><span class="o">.</span><span class="n">nodes</span><span class="p">:</span>
        <span class="n">rank_sum</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">neighbor</span> <span class="ow">in</span> <span class="n">G</span><span class="o">.</span><span class="n">neighbors</span><span class="p">(</span><span class="n">node</span><span class="p">):</span>
            <span class="n">neighbor_outdegree</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">neighbors</span><span class="p">(</span><span class="n">neighbor</span><span class="p">)))</span>
            <span class="n">rank_sum</span> <span class="o">+=</span> <span class="n">pagerank</span><span class="p">[</span><span class="n">neighbor</span><span class="p">]</span> <span class="o">/</span> <span class="n">neighbor_outdegree</span>

        <span class="c1"># Hitung PageRank baru menggunakan rumus</span>
        <span class="n">new_pagerank</span><span class="p">[</span><span class="n">node</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">damping_factor</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">nodes</span><span class="p">)</span> <span class="o">+</span> <span class="n">damping_factor</span> <span class="o">*</span> <span class="n">rank_sum</span>

        <span class="c1"># Cetak langkah-langkah perhitungan PageRank untuk setiap node</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - Kalimat </span><span class="si">{</span><span class="n">node</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">: (</span><span class="si">{</span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">damping_factor</span><span class="p">)</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">nodes</span><span class="p">)</span><span class="si">}</span><span class="s2">) + (</span><span class="si">{</span><span class="n">damping_factor</span><span class="si">}</span><span class="s2"> * </span><span class="si">{</span><span class="n">rank_sum</span><span class="si">}</span><span class="s2">) = </span><span class="si">{</span><span class="n">new_pagerank</span><span class="p">[</span><span class="n">node</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Perbarui nilai PageRank</span>
    <span class="n">pagerank</span> <span class="o">=</span> <span class="n">new_pagerank</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Menampilkan hasil PageRank akhir</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Hasil Akhir PageRank:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">node</span><span class="p">,</span> <span class="n">rank</span> <span class="ow">in</span> <span class="n">pagerank</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Kalimat </span><span class="si">{</span><span class="n">node</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Iterasi 1:
  - Kalimat 1: (0.15000000000000002/12) + (0.85 * 0.10793650793650793) = 0.10424603174603174
  - Kalimat 2: (0.15000000000000002/12) + (0.85 * 0.10793650793650791) = 0.10424603174603173
  - Kalimat 3: (0.15000000000000002/12) + (0.85 * 0.09682539682539681) = 0.09480158730158729
  - Kalimat 8: (0.15000000000000002/12) + (0.85 * 0.10317460317460317) = 0.10019841269841269
  - Kalimat 9: (0.15000000000000002/12) + (0.85 * 0.10793650793650794) = 0.10424603174603174
  - Kalimat 10: (0.15000000000000002/12) + (0.85 * 0.14880952380952378) = 0.13898809523809522
  - Kalimat 12: (0.15000000000000002/12) + (0.85 * 0.08095238095238094) = 0.08130952380952379
  - Kalimat 13: (0.15000000000000002/12) + (0.85 * 0.04246031746031746) = 0.048591269841269845
  - Kalimat 4: (0.15000000000000002/12) + (0.85 * 0.13293650793650794) = 0.12549603174603174
  - Kalimat 7: (0.15000000000000002/12) + (0.85 * 0.037698412698412696) = 0.044543650793650795
  - Kalimat 6: (0.15000000000000002/12) + (0.85 * 0.016666666666666666) = 0.02666666666666667
  - Kalimat 11: (0.15000000000000002/12) + (0.85 * 0.016666666666666666) = 0.02666666666666667


Iterasi 2:
  - Kalimat 1: (0.15000000000000002/12) + (0.85 * 0.1175736961451247) = 0.11243764172335599
  - Kalimat 2: (0.15000000000000002/12) + (0.85 * 0.11352607709750566) = 0.1089971655328798
  - Kalimat 3: (0.15000000000000002/12) + (0.85 * 0.12782501889644746) = 0.12115126606198033
  - Kalimat 8: (0.15000000000000002/12) + (0.85 * 0.08926492819349961) = 0.08837518896447466
  - Kalimat 9: (0.15000000000000002/12) + (0.85 * 0.11352607709750566) = 0.1089971655328798
  - Kalimat 10: (0.15000000000000002/12) + (0.85 * 0.08485071806500377) = 0.0846231103552532
  - Kalimat 12: (0.15000000000000002/12) + (0.85 * 0.11111678004535146) = 0.10694926303854874
  - Kalimat 13: (0.15000000000000002/12) + (0.85 * 0.059389644746787595) = 0.06298119803476945
  - Kalimat 4: (0.15000000000000002/12) + (0.85 * 0.08354591836734693) = 0.08351403061224488
  - Kalimat 7: (0.15000000000000002/12) + (0.85 * 0.046484315948601654) = 0.05201166855631141
  - Kalimat 6: (0.15000000000000002/12) + (0.85 * 0.02509920634920635) = 0.0338343253968254
  - Kalimat 11: (0.15000000000000002/12) + (0.85 * 0.027797619047619043) = 0.03612797619047619


Iterasi 3:
  - Kalimat 1: (0.15000000000000002/12) + (0.85 * 0.11892180110139292) = 0.11358353093618398
  - Kalimat 2: (0.15000000000000002/12) + (0.85 * 0.11553497192527803) = 0.11070472613648633
  - Kalimat 3: (0.15000000000000002/12) + (0.85 * 0.11338607106863909) = 0.10887816040834322
  - Kalimat 8: (0.15000000000000002/12) + (0.85 * 0.10284284679480257) = 0.09991641977558219
  - Kalimat 9: (0.15000000000000002/12) + (0.85 * 0.11553497192527803) = 0.11070472613648633
  - Kalimat 10: (0.15000000000000002/12) + (0.85 * 0.1083164300111579) = 0.1045689655094842
  - Kalimat 12: (0.15000000000000002/12) + (0.85 * 0.0981393194579419) = 0.0959184215392506
  - Kalimat 13: (0.15000000000000002/12) + (0.85 * 0.04771634047799013) = 0.053058889406291616
  - Kalimat 4: (0.15000000000000002/12) + (0.85 * 0.10010857358816543) = 0.0975922875499406
  - Kalimat 7: (0.15000000000000002/12) + (0.85 * 0.04587124545585429) = 0.05149055863747615
  - Kalimat 6: (0.15000000000000002/12) + (0.85 * 0.016702806122448975) = 0.02669738520408163
  - Kalimat 11: (0.15000000000000002/12) + (0.85 * 0.01692462207105064) = 0.026885928760393047


Iterasi 4:
  - Kalimat 1: (0.15000000000000002/12) + (0.85 * 0.11842317445855893) = 0.11315969828977508
  - Kalimat 2: (0.15000000000000002/12) + (0.85 * 0.11691631977223996) = 0.11187887180640396
  - Kalimat 3: (0.15000000000000002/12) + (0.85 * 0.12092753128947471) = 0.1152884015960535
  - Kalimat 8: (0.15000000000000002/12) + (0.85 * 0.0982599793885178) = 0.09602098248024013
  - Kalimat 9: (0.15000000000000002/12) + (0.85 * 0.11691631977223996) = 0.11187887180640396
  - Kalimat 10: (0.15000000000000002/12) + (0.85 * 0.09233887043967876) = 0.09098803987372693
  - Kalimat 12: (0.15000000000000002/12) + (0.85 * 0.10384241398581351) = 0.10076605188794148
  - Kalimat 13: (0.15000000000000002/12) + (0.85 * 0.05379274843632968) = 0.058223836170880235
  - Kalimat 4: (0.15000000000000002/12) + (0.85 * 0.08986773346271615) = 0.08888757344330872
  - Kalimat 7: (0.15000000000000002/12) + (0.85 * 0.0482826583825455) = 0.05354025962516368
  - Kalimat 6: (0.15000000000000002/12) + (0.85 * 0.01951845750998812) = 0.029090688883489903
  - Kalimat 11: (0.15000000000000002/12) + (0.85 * 0.02091379310189684) = 0.030276724136612317


Iterasi 5:
  - Kalimat 1: (0.15000000000000002/12) + (0.85 * 0.11883855602766832) = 0.11351277262351807
  - Kalimat 2: (0.15000000000000002/12) + (0.85 * 0.11704024577158932) = 0.11198420890585092
  - Kalimat 3: (0.15000000000000002/12) + (0.85 * 0.11690402485371117) = 0.11186842112565448
  - Kalimat 8: (0.15000000000000002/12) + (0.85 * 0.10185553338420081) = 0.09907720337657068
  - Kalimat 9: (0.15000000000000002/12) + (0.85 * 0.11704024577158932) = 0.11198420890585092
  - Kalimat 10: (0.15000000000000002/12) + (0.85 * 0.09911445434906196) = 0.09674728619670267
  - Kalimat 12: (0.15000000000000002/12) + (0.85 * 0.10057595744892663) = 0.09798956383158762
  - Kalimat 13: (0.15000000000000002/12) + (0.85 * 0.05036677623903899) = 0.05531175980318315
  - Kalimat 4: (0.15000000000000002/12) + (0.85 * 0.09432019446607941) = 0.0926721652961675
  - Kalimat 7: (0.15000000000000002/12) + (0.85 * 0.04796888902472686) = 0.05327355567101783
  - Kalimat 6: (0.15000000000000002/12) + (0.85 * 0.017777514688661743) = 0.027610887485362483
  - Kalimat 11: (0.15000000000000002/12) + (0.85 * 0.018197607974745386) = 0.02796796677853358


Iterasi 6:
  - Kalimat 1: (0.15000000000000002/12) + (0.85 * 0.11860786298519316) = 0.11331668353741418
  - Kalimat 2: (0.15000000000000002/12) + (0.85 * 0.11733180367307872) = 0.11223203312211691
  - Kalimat 3: (0.15000000000000002/12) + (0.85 * 0.11893995013353659) = 0.1135989576135061
  - Kalimat 8: (0.15000000000000002/12) + (0.85 * 0.10038790680962048) = 0.09782972078817741
  - Kalimat 9: (0.15000000000000002/12) + (0.85 * 0.11733180367307872) = 0.11223203312211691
  - Kalimat 10: (0.15000000000000002/12) + (0.85 * 0.0949341274109315) = 0.09319400829929177
  - Kalimat 12: (0.15000000000000002/12) + (0.85 * 0.10207669195012752) = 0.09926518815760839
  - Kalimat 13: (0.15000000000000002/12) + (0.85 * 0.05207843484355727) = 0.05676666961702369
  - Kalimat 4: (0.15000000000000002/12) + (0.85 * 0.09191917273405895) = 0.0906312968239501
  - Kalimat 7: (0.15000000000000002/12) + (0.85 * 0.04850835548824299) = 0.05373210216500655
  - Kalimat 6: (0.15000000000000002/12) + (0.85 * 0.0185344330592335) = 0.02825426810034848
  - Kalimat 11: (0.15000000000000002/12) + (0.85 * 0.019349457239340534) = 0.028947038653439457


Iterasi 7:
  - Kalimat 1: (0.15000000000000002/12) + (0.85 * 0.11870489405046006) = 0.11339915994289104
  - Kalimat 2: (0.15000000000000002/12) + (0.85 * 0.1173357793307142) = 0.11223541243110706
  - Kalimat 3: (0.15000000000000002/12) + (0.85 * 0.11786860534156239) = 0.11268831454032803
  - Kalimat 8: (0.15000000000000002/12) + (0.85 * 0.10131573926950828) = 0.09861837837908204
  - Kalimat 9: (0.15000000000000002/12) + (0.85 * 0.11733577933071421) = 0.11223541243110707
  - Kalimat 10: (0.15000000000000002/12) + (0.85 * 0.09682998004979926) = 0.09480548304232936
  - Kalimat 12: (0.15000000000000002/12) + (0.85 * 0.10124787636681323) = 0.09856069491179124
  - Kalimat 13: (0.15000000000000002/12) + (0.85 * 0.05113185277275661) = 0.05596207485684312
  - Kalimat 4: (0.15000000000000002/12) + (0.85 * 0.09309318382057939) = 0.09162920624749248
  - Kalimat 7: (0.15000000000000002/12) + (0.85 * 0.048371248642443916) = 0.05361556134607733
  - Kalimat 6: (0.15000000000000002/12) + (0.85 * 0.01812625936479002) = 0.02790732046007152
  - Kalimat 11: (0.15000000000000002/12) + (0.85 * 0.018638801659858352) = 0.028342981410879604


Iterasi 8:
  - Kalimat 1: (0.15000000000000002/12) + (0.85 * 0.11864389178577943) = 0.11334730801791251
  - Kalimat 2: (0.15000000000000002/12) + (0.85 * 0.11739271490109736) = 0.11228380766593275
  - Kalimat 3: (0.15000000000000002/12) + (0.85 * 0.11841725742622017) = 0.11315466881228714
  - Kalimat 8: (0.15000000000000002/12) + (0.85 * 0.10089135006936871) = 0.09825764755896339
  - Kalimat 9: (0.15000000000000002/12) + (0.85 * 0.11739271490109736) = 0.11228380766593275
  - Kalimat 10: (0.15000000000000002/12) + (0.85 * 0.09572199948891905) = 0.09386369956558119
  - Kalimat 12: (0.15000000000000002/12) + (0.85 * 0.10165240919302626) = 0.09890454781407232
  - Kalimat 13: (0.15000000000000002/12) + (0.85 * 0.05159737299682112) = 0.05635776704729795
  - Kalimat 4: (0.15000000000000002/12) + (0.85 * 0.09249969428859037) = 0.09112474014530181
  - Kalimat 7: (0.15000000000000002/12) + (0.85 * 0.04850365709111569) = 0.05372810852744834
  - Kalimat 6: (0.15000000000000002/12) + (0.85 * 0.018325841249498494) = 0.028076965062073724
  - Kalimat 11: (0.15000000000000002/12) + (0.85 * 0.01896109660846587) = 0.028616932117195994


Iterasi 9:
  - Kalimat 1: (0.15000000000000002/12) + (0.85 * 0.11866506874974332) = 0.11336530843728182
  - Kalimat 2: (0.15000000000000002/12) + (0.85 * 0.11739265264744898) = 0.11228375475033163
  - Kalimat 3: (0.15000000000000002/12) + (0.85 * 0.11813161431622228) = 0.11291187216878894
  - Kalimat 8: (0.15000000000000002/12) + (0.85 * 0.10113380502425806) = 0.09846373427061934
  - Kalimat 9: (0.15000000000000002/12) + (0.85 * 0.11739265264744898) = 0.11228375475033163
  - Kalimat 10: (0.15000000000000002/12) + (0.85 * 0.0962443710300978) = 0.09430771537558312
  - Kalimat 12: (0.15000000000000002/12) + (0.85 * 0.10143620110818591) = 0.09872077094195801
  - Kalimat 13: (0.15000000000000002/12) + (0.85 * 0.05134148708026431) = 0.05614026401822467
  - Kalimat 4: (0.15000000000000002/12) + (0.85 * 0.09280709695644092) = 0.09138603241297477
  - Kalimat 7: (0.15000000000000002/12) + (0.85 * 0.04845736249771278) = 0.05368875812305587
  - Kalimat 6: (0.15000000000000002/12) + (0.85 * 0.018224948029060363) = 0.027991205824701312
  - Kalimat 11: (0.15000000000000002/12) + (0.85 * 0.01877273991311624) = 0.028456828926148807


Iterasi 10:
  - Kalimat 1: (0.15000000000000002/12) + (0.85 * 0.11865038885511424) = 0.1133528305268471
  - Kalimat 2: (0.15000000000000002/12) + (0.85 * 0.11740339130043397) = 0.11229288260536886
  - Kalimat 3: (0.15000000000000002/12) + (0.85 * 0.11827895060808569) = 0.11303710801687283
  - Kalimat 8: (0.15000000000000002/12) + (0.85 * 0.1010160583480555) = 0.09836364959584717
  - Kalimat 9: (0.15000000000000002/12) + (0.85 * 0.11740339130043395) = 0.11229288260536885
  - Kalimat 10: (0.15000000000000002/12) + (0.85 * 0.09594902360436966) = 0.09405667006371421
  - Kalimat 12: (0.15000000000000002/12) + (0.85 * 0.10154513385867359) = 0.09881336377987254
  - Kalimat 13: (0.15000000000000002/12) + (0.85 * 0.05146720951602201) = 0.05624712808861871
  - Kalimat 4: (0.15000000000000002/12) + (0.85 * 0.09265600788685416) = 0.09125760670382603
  - Kalimat 7: (0.15000000000000002/12) + (0.85 * 0.04849169516424559) = 0.05371794088960875
  - Kalimat 6: (0.15000000000000002/12) + (0.85 * 0.018277206482594954) = 0.028035625510205713
  - Kalimat 11: (0.15000000000000002/12) + (0.85 * 0.018861543075116623) = 0.02853231161384913


Hasil Akhir PageRank:
Kalimat 1: 0.1133528305268471
Kalimat 2: 0.11229288260536886
Kalimat 3: 0.11303710801687283
Kalimat 8: 0.09836364959584717
Kalimat 9: 0.11229288260536885
Kalimat 10: 0.09405667006371421
Kalimat 12: 0.09881336377987254
Kalimat 13: 0.05624712808861871
Kalimat 4: 0.09125760670382603
Kalimat 7: 0.05371794088960875
Kalimat 6: 0.028035625510205713
Kalimat 11: 0.02853231161384913
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Matriks TF-IDF telah dihitung sebelumnya (tfidf_matrix)</span>
<span class="c1"># Hitung cosine similarity antara semua pasangan kalimat</span>
<span class="n">similarity_matrix</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">tfidf_matrix</span><span class="p">,</span> <span class="n">tfidf_matrix</span><span class="p">)</span>

<span class="c1"># Nama kolom dan indeks untuk DataFrame</span>
<span class="n">sentence_indices</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;Kalimat </span><span class="si">{</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">))]</span>

<span class="c1"># Buat DataFrame dari hasil cosine similarity</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">similarity_matrix</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">sentence_indices</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">sentence_indices</span><span class="p">)</span>

<span class="c1"># Membuat grafik matriks</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">cax</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">cax</span><span class="p">)</span>

<span class="c1"># Memberi label pada sumbu X dan Y</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">)))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

<span class="c1"># Menampilkan nilai similarity pada matriks</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">)):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)):</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">df</span><span class="o">.</span><span class="n">iat</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="p">]</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/5a1819ab316b76a8994d68abb8c661f8306cea74229d6debc153e71a25094eea.png" src="_images/5a1819ab316b76a8994d68abb8c661f8306cea74229d6debc153e71a25094eea.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>

<span class="c1"># Buat grafik dari matriks similarity</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>

<span class="c1"># Tambahkan simpul (node) ke grafik yang mewakili setiap kalimat</span>
<span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">:</span>
    <span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>

<span class="c1"># Tambahkan tepi (edge) antara kalimat berdasarkan similarity</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">)):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">)):</span>
        <span class="n">similarity</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>  <span class="c1"># Mengambil similarity dari DataFrame</span>
        <span class="k">if</span> <span class="n">similarity</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">sentences</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">sentences</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">weight</span><span class="o">=</span><span class="n">similarity</span><span class="p">)</span>

<span class="c1"># Hitung closeness centrality untuk setiap simpul</span>
<span class="n">closeness_centrality</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">closeness_centrality</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">distance</span><span class="o">=</span><span class="s1">&#39;weight&#39;</span><span class="p">)</span>

<span class="c1"># Cetak closeness centrality</span>
<span class="k">for</span> <span class="n">sentence</span><span class="p">,</span> <span class="n">centrality</span> <span class="ow">in</span> <span class="n">closeness_centrality</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Closeness Centrality of </span><span class="si">{</span><span class="n">sentence</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">centrality</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Closeness Centrality of 
				jakarta antara  jaksa penuntut umum jpu pada kejaksaan agung kejagung ri menuntut account director of integrated account departement pt huawei tech investment mukti ali selama  tahun dan membayar denda rp juta subsider  bulan pidana kurungan dalam perkara korupsi bts g kementerian komunikasi dan informatika kemenkominfo.: 10.7806
Closeness Centrality of menjatuhkan pidana terhadap terdakwa mukti ali selama  tahun dikurangi sepenuhnya dengan lamanya terdakwa ditahan dengan perintah agar terdakwa tetap dilakukan penahanan di rutan kata jaksa dalam persidangan di pengadilan tindak pidana korupsi tipikor pada pengadilan negeri jakarta pusat senin.: 8.8419
Closeness Centrality of jaksa menyatakan bahwa terdakwa mukti ali terbukti secara sah dan meyakinkan bersalah menurut hukum turut serta dalam melakukan tindak pidana korupsi bts g kementerian komunikasi dan informatika kemenkominfo.: 8.3432
Closeness Centrality of mukti didakwa telah melanggar pasal  ayat  juncto pasal  undangundang nomor  tahun  tentang pemberantasan tindak pidana korupsi sebagaimana diubah dengan uu no.: 11.9165
Closeness Centrality of tahun  jo.: 0.0000
Closeness Centrality of pasal  ayat  ke kuhp.: 2.0375
Closeness Centrality of sementara itu halhal yang memberatkan terdakwa adalah perbuatannya tidak mendukung program pemerintah dalam rangka penyelenggaraan negara yang bersih dari korupsi kolusi dan nepotisme.: 11.5177
Closeness Centrality of perbuatan terdakwa bersamasama dengan terdakwa lain telah mengakibatkan kerugian keuangan negara sebesar rp.... ungkap jaksa.: 8.6604
Closeness Centrality of adapun halhal yang meringankan mukti ali adalah terdakwa belum pernah dihukum bersikap sopan selama persidangan dan tidak menikmati hasil dari tindak pidana korupsi.: 9.8221
Closeness Centrality of baca juga irwan hermawan dituntut  tahun penjara terkait korupsi bts g
baca juga galumbang menak dituntut  tahun penjara dalam kasus bts g
 
sidang tuntutan ini digelar bersamaan dengan tuntutan dua terdakwa lainnya yakni komisaris pt solitech media sinergy irwan hermawan dan eks direktur utama pt mora telematika indonesia galumbang menak simanjuntak.: 11.6522
Closeness Centrality of irwan hermawan dituntut pidana penjara selama  tahun sementara galumbang menak dituntut  tahun.: 11.8727
Closeness Centrality of para terdakwa diduga melakukan tindak pidana korupsi penyediaan infrastruktur base transceiver station bts g dan infrastruktur pendukung paket     dan  bakti kemenkominfo pada tahun .: 9.2802
Closeness Centrality of pada surat dakwaan disebutkan bahwa sejumlah pihak mendapat keuntungan dari proyek pembangunan tersebut yaitu mantan menteri kominfo johnny g. plate menerima uang sebesar rp... mantan direktur utama bakti kominfo anang achmad latif menerima uang rp miliar dan tenaga ahli human development universitas indonesia yohan suryanto menerima rp...
 

selanjutnya irwan hermawan selaku komisaris pt solitechmedia sinergy menerima rp miliar windi purnama selaku direktur pt multimedia berdikari sejahtera menerima rp juta muhammad yusrizki selaku direktur pt basis utama prima menerima rp miliar dan  juta dolar as konsorsium fiberhome pt telkominfra pt multi trans data pt mtd untuk paket  dan  menerima rp.... konsorsium lintasarta huawei sei untuk paket  menerima rp.... dan konsorsium ibs dan zte paket  dan  mendapat rp.....pewarta rivan awal linggaeditor d.dj.: 8.6417
Closeness Centrality of kliwantoro				copyright  antara: 0.0000
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>

<span class="c1"># Matriks TF-IDF telah dihitung sebelumnya (tfidf_matrix)</span>
<span class="c1"># Hitung cosine similarity antara semua pasangan kalimat</span>
<span class="n">similarity_matrix</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">tfidf_matrix</span><span class="p">,</span> <span class="n">tfidf_matrix</span><span class="p">)</span>

<span class="c1"># Buat grafik berarah (DiGraph) berdasarkan similarity_matrix</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">DiGraph</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">similarity_matrix</span><span class="p">)):</span>
    <span class="n">G</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>  <span class="c1"># Tambahkan node dengan indeks numerik</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">similarity_matrix</span><span class="p">)):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">similarity_matrix</span><span class="p">)):</span>
        <span class="n">similarity</span> <span class="o">=</span> <span class="n">similarity_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">similarity</span> <span class="o">&gt;</span> <span class="mf">0.15</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">j</span><span class="p">:</span>  <span class="c1"># Pastikan node tidak menghubungkan dirinya sendiri</span>
            <span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>

<span class="c1"># Hitung closeness centrality</span>
<span class="n">closeness_centrality</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">closeness_centrality</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>

<span class="c1"># Visualisasi closeness centrality</span>
<span class="n">pos</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">spring_layout</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>  <span class="c1"># Atur layout grafik</span>
<span class="n">node_size</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span> <span class="o">*</span> <span class="mi">1000</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">closeness_centrality</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>  <span class="c1"># Ubah ukuran node berdasarkan closeness centrality, dengan faktor pengurangan ukuran</span>

<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx_nodes</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">node_size</span><span class="o">=</span><span class="n">node_size</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx_edges</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">edge_color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">arrows</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx_labels</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/7cec64f10e7d33e66d784e64978c470af0763506fb29418111942be38dcd6575.png" src="_images/7cec64f10e7d33e66d784e64978c470af0763506fb29418111942be38dcd6575.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Cetak closeness centrality</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Closeness Centrality:&quot;</span><span class="p">)</span>
<span class="c1"># for node, closeness in closeness_centrality.items():</span>
<span class="c1">#     print(f&quot;Node {node}: {closeness:.4f}&quot;)</span>
<span class="n">sorted_closeness</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">closeness_centrality</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">item</span><span class="p">:</span> <span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="k">for</span> <span class="n">node</span><span class="p">,</span> <span class="n">closeness</span> <span class="ow">in</span> <span class="n">sorted_closeness</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Node </span><span class="si">{</span><span class="n">node</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">closeness</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Closeness Centrality:
Node 2: 0.3205
Node 1: 0.2747
Node 8: 0.2404
Node 0: 0.1923
Node 11: 0.1923
Node 7: 0.1748
Node 9: 0.1538
Node 10: 0.1026
Node 12: 0.1026
Node 3: 0.0769
Node 5: 0.0769
Node 4: 0.0000
Node 6: 0.0000
Node 13: 0.0000
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Cetak closeness centrality</span>
<span class="n">top_3_closeness</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">sorted_closeness</span><span class="o">.</span><span class="n">items</span><span class="p">())[:</span><span class="mi">3</span><span class="p">]</span>

<span class="c1"># Memasukkan 3 kalimat teratas dan informasi node ke dalam DataFrame</span>
<span class="n">datacl</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Node&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">node</span> <span class="k">for</span> <span class="n">node</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">top_3_closeness</span><span class="p">],</span>
    <span class="s2">&quot;Closeness Centrality&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">closeness</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">closeness</span> <span class="ow">in</span> <span class="n">top_3_closeness</span><span class="p">],</span>
    <span class="s2">&quot;Kalimat&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">sentences</span><span class="p">[</span><span class="n">node</span><span class="p">]</span> <span class="k">for</span> <span class="n">node</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">top_3_closeness</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">df_top_3</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">datacl</span><span class="p">)</span>

<span class="c1"># Cetak DataFrame</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tiga Node Closeness Teratas&quot;</span><span class="p">)</span>
<span class="n">df_top_3</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Tiga Node Closeness Teratas
</pre></div>
</div>
<div class="output text_html">
  <div id="df-f6dac596-894a-4b62-8648-fee0427fc7d7" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Node</th>
      <th>Closeness Centrality</th>
      <th>Kalimat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2</td>
      <td>0.320513</td>
      <td>jaksa menyatakan bahwa terdakwa mukti ali terb...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>0.274725</td>
      <td>menjatuhkan pidana terhadap terdakwa mukti ali...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>8</td>
      <td>0.240385</td>
      <td>adapun halhal yang meringankan mukti ali adala...</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">
      
  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-f6dac596-894a-4b62-8648-fee0427fc7d7')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">
      
  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>
    
  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-f6dac596-894a-4b62-8648-fee0427fc7d7 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-f6dac596-894a-4b62-8648-fee0427fc7d7');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>
  
    </div>
  </div>
  </div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Hitung PageRank</span>
<span class="n">pagerank</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">pagerank</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>

<span class="c1"># Cetak PageRank dalam urutan dari terbesar ke terkecil</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;PageRank :&quot;</span><span class="p">)</span>
<span class="n">sorted_pagerank</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">pagerank</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">item</span><span class="p">:</span> <span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="k">for</span> <span class="n">node</span><span class="p">,</span> <span class="n">rank</span> <span class="ow">in</span> <span class="n">sorted_pagerank</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Node </span><span class="si">{</span><span class="n">node</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">rank</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>PageRank :
Node 2: 0.1674
Node 9: 0.1275
Node 1: 0.1260
Node 3: 0.0873
Node 5: 0.0873
Node 8: 0.0844
Node 10: 0.0673
Node 12: 0.0673
Node 7: 0.0488
Node 0: 0.0487
Node 11: 0.0487
Node 4: 0.0131
Node 6: 0.0131
Node 13: 0.0131
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Cetak closeness centrality</span>
<span class="n">top_3_pagerank</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">sorted_pagerank</span><span class="o">.</span><span class="n">items</span><span class="p">())[:</span><span class="mi">3</span><span class="p">]</span>

<span class="c1"># Memasukkan 3 kalimat teratas dan informasi node ke dalam DataFrame</span>
<span class="n">datapg</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Node&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">node</span> <span class="k">for</span> <span class="n">node</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">top_3_pagerank</span><span class="p">],</span>
    <span class="s2">&quot;Pagerank&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">rank</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">rank</span> <span class="ow">in</span> <span class="n">top_3_pagerank</span><span class="p">],</span>
    <span class="s2">&quot;Kalimat&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">sentences</span><span class="p">[</span><span class="n">node</span><span class="p">]</span> <span class="k">for</span> <span class="n">node</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">top_3_pagerank</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">df_top_3pg</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">datapg</span><span class="p">)</span>

<span class="c1"># Cetak DataFrame</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tiga Node Pagerank Teratas&quot;</span><span class="p">)</span>
<span class="n">df_top_3pg</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Tiga Node Pagerank Teratas
</pre></div>
</div>
<div class="output text_html">
  <div id="df-fa5508f7-ad9c-4861-b918-d0c09a0f7349" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Node</th>
      <th>Pagerank</th>
      <th>Kalimat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2</td>
      <td>0.167429</td>
      <td>jaksa menyatakan bahwa terdakwa mukti ali terb...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>9</td>
      <td>0.127461</td>
      <td>baca juga irwan hermawan dituntut  tahun penja...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>0.126032</td>
      <td>menjatuhkan pidana terhadap terdakwa mukti ali...</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">
      
  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-fa5508f7-ad9c-4861-b918-d0c09a0f7349')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">
      
  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>
    
  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-fa5508f7-ad9c-4861-b918-d0c09a0f7349 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-fa5508f7-ad9c-4861-b918-d0c09a0f7349');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>
  
    </div>
  </div>
  </div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Hitung betweenness centrality</span>
<span class="n">betweenness</span><span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">betweenness_centrality</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>

<span class="c1"># Cetak DataFrame</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;DataFrame Betweenness Centrality:&quot;</span><span class="p">)</span>
<span class="n">sorted_betweenness</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">betweenness</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">item</span><span class="p">:</span> <span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="k">for</span> <span class="n">node</span><span class="p">,</span> <span class="n">between</span> <span class="ow">in</span> <span class="n">sorted_betweenness</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Node </span><span class="si">{</span><span class="n">node</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">between</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DataFrame Betweenness Centrality:
Node 2: 0.0897
Node 1: 0.0513
Node 9: 0.0128
Node 0: 0.0000
Node 3: 0.0000
Node 4: 0.0000
Node 5: 0.0000
Node 6: 0.0000
Node 7: 0.0000
Node 8: 0.0000
Node 10: 0.0000
Node 11: 0.0000
Node 12: 0.0000
Node 13: 0.0000
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Cetak closeness centrality</span>
<span class="n">top_3_between</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">sorted_betweenness</span><span class="o">.</span><span class="n">items</span><span class="p">())[:</span><span class="mi">3</span><span class="p">]</span>

<span class="c1"># Memasukkan 3 kalimat teratas dan informasi node ke dalam DataFrame</span>
<span class="n">databw</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Node&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">node</span> <span class="k">for</span> <span class="n">node</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">top_3_between</span><span class="p">],</span>
    <span class="s2">&quot;Between&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">between</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">between</span> <span class="ow">in</span> <span class="n">top_3_between</span><span class="p">],</span>
    <span class="s2">&quot;Kalimat&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">sentences</span><span class="p">[</span><span class="n">node</span><span class="p">]</span> <span class="k">for</span> <span class="n">node</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">top_3_between</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">df_top_3bw</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">databw</span><span class="p">)</span>

<span class="c1"># Cetak DataFrame</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tiga Node Between Teratas&quot;</span><span class="p">)</span>
<span class="n">df_top_3bw</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Tiga Node Between Teratas
</pre></div>
</div>
<div class="output text_html">
  <div id="df-3f6c1898-8fbf-4883-b296-e5b86dd8c718" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Node</th>
      <th>Between</th>
      <th>Kalimat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2</td>
      <td>0.089744</td>
      <td>jaksa menyatakan bahwa terdakwa mukti ali terb...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>0.051282</td>
      <td>menjatuhkan pidana terhadap terdakwa mukti ali...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>9</td>
      <td>0.012821</td>
      <td>baca juga irwan hermawan dituntut  tahun penja...</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">
      
  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-3f6c1898-8fbf-4883-b296-e5b86dd8c718')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">
      
  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>
    
  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-3f6c1898-8fbf-4883-b296-e5b86dd8c718 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-3f6c1898-8fbf-4883-b296-e5b86dd8c718');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>
  
    </div>
  </div>
  </div></div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="Modelling_LDA.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Modelling LDA</p>
      </div>
    </a>
    <a class="right-next"
       href="Perhitungan_PageRank.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">PageRank</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Crawling Berita</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#import-library"><strong>Import Library</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#proses-crawling-berita"><strong>Proses Crawling Berita</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#preprocessing"><strong>Preprocessing</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#tf-idf"><strong>TF-IDF</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#cosine-similarity"><strong>Cosine Similarity</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#closeness-centrality"><strong>Closeness Centrality</strong></a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Aderisa Dyta Okvianti
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>